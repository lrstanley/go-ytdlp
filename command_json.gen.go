// Copyright (c) Liam Stanley <liam@liam.sh>. All rights reserved. Use of
// this source code is governed by the MIT license that can be found in
// the LICENSE file.
//
// Code generated by cmd/codegen. DO NOT EDIT.

package ytdlp

import (
	"encoding/json"
	"errors"
	"fmt"
	"slices"
)

// FlagConfig holds all information for the flags in which to use for yt-dlp. Note that
// you can technically set multiple conflicting flags through this type, however, when
// the [FlagConfig.Validate] method is called, it will return a [ErrMultipleJSONParsingFlags]
// error if there are any conflicts.
type FlagConfig struct {
	General             FlagsGeneral             `json:"general,omitempty,omitzero" jsonschema:"title=Group General"`
	Network             FlagsNetwork             `json:"network,omitempty,omitzero" jsonschema:"title=Group Network"`
	GeoRestriction      FlagsGeoRestriction      `json:"geo_restriction,omitempty,omitzero" jsonschema:"title=Group GeoRestriction"`
	VideoSelection      FlagsVideoSelection      `json:"video_selection,omitempty,omitzero" jsonschema:"title=Group VideoSelection"`
	Download            FlagsDownload            `json:"download,omitempty,omitzero" jsonschema:"title=Group Download"`
	Filesystem          FlagsFilesystem          `json:"filesystem,omitempty,omitzero" jsonschema:"title=Group Filesystem"`
	Thumbnail           FlagsThumbnail           `json:"thumbnail,omitempty,omitzero" jsonschema:"title=Group Thumbnail"`
	InternetShortcut    FlagsInternetShortcut    `json:"internet_shortcut,omitempty,omitzero" jsonschema:"title=Group InternetShortcut"`
	VerbositySimulation FlagsVerbositySimulation `json:"verbosity_simulation,omitempty,omitzero" jsonschema:"title=Group VerbositySimulation"`
	Workarounds         FlagsWorkarounds         `json:"workarounds,omitempty,omitzero" jsonschema:"title=Group Workarounds"`
	VideoFormat         FlagsVideoFormat         `json:"video_format,omitempty,omitzero" jsonschema:"title=Group VideoFormat"`
	Subtitle            FlagsSubtitle            `json:"subtitle,omitempty,omitzero" jsonschema:"title=Group Subtitle"`
	Authentication      FlagsAuthentication      `json:"authentication,omitempty,omitzero" jsonschema:"title=Group Authentication"`
	PostProcessing      FlagsPostProcessing      `json:"post_processing,omitempty,omitzero" jsonschema:"title=Group PostProcessing"`
	SponsorBlock        FlagsSponsorBlock        `json:"sponsor_block,omitempty,omitzero" jsonschema:"title=Group SponsorBlock"`
	Extractor           FlagsExtractor           `json:"extractor,omitempty,omitzero" jsonschema:"title=Group Extractor"`
}

// Clone returns a copy of the flag config.
func (f *FlagConfig) Clone() *FlagConfig {
	// This panics if the flag config is invalid, which is a programming error, as there should be
	// no reason the config can have non-serializable values.
	v := &FlagConfig{}
	b, err := json.Marshal(f)
	if err != nil {
		panic(err)
	}
	err = json.Unmarshal(b, v)
	if err != nil {
		panic(err)
	}
	return v
}

// Validate runs validation across all flag groups. If there are validation-specific
// errors, they will be returned as a [ErrMultipleJSONParsingFlags] error. Otherwise,
// any other errors will be returned as a regular wrapped errors.
func (f *FlagConfig) Validate() error {
	errs := []error{
		f.General.Validate(),
		f.Network.Validate(),
		f.GeoRestriction.Validate(),
		f.VideoSelection.Validate(),
		f.Download.Validate(),
		f.Filesystem.Validate(),
		f.Thumbnail.Validate(),
		f.InternetShortcut.Validate(),
		f.VerbositySimulation.Validate(),
		f.Workarounds.Validate(),
		f.VideoFormat.Validate(),
		f.Subtitle.Validate(),
		f.Authentication.Validate(),
		f.PostProcessing.Validate(),
		f.SponsorBlock.Validate(),
		f.Extractor.Validate(),
	}

	var regularErrs []error
	var validationErrs []*ErrJSONParsingFlag

	for _, err := range errs {
		if err == nil {
			continue
		}
		if verr, ok := IsJSONParsingFlagError(err); ok {
			validationErrs = append(validationErrs, verr)
		} else {
			regularErrs = append(regularErrs, err)
		}
	}

	if len(validationErrs) > 0 {
		return &ErrMultipleJSONParsingFlags{Errors: validationErrs}
	}
	if len(regularErrs) > 0 {
		return errors.Join(regularErrs...)
	}
	return nil
}

func (f *FlagConfig) ToFlags() (flags Flags) {
	flags = append(flags, f.General.ToFlags()...)
	flags = append(flags, f.Network.ToFlags()...)
	flags = append(flags, f.GeoRestriction.ToFlags()...)
	flags = append(flags, f.VideoSelection.ToFlags()...)
	flags = append(flags, f.Download.ToFlags()...)
	flags = append(flags, f.Filesystem.ToFlags()...)
	flags = append(flags, f.Thumbnail.ToFlags()...)
	flags = append(flags, f.InternetShortcut.ToFlags()...)
	flags = append(flags, f.VerbositySimulation.ToFlags()...)
	flags = append(flags, f.Workarounds.ToFlags()...)
	flags = append(flags, f.VideoFormat.ToFlags()...)
	flags = append(flags, f.Subtitle.ToFlags()...)
	flags = append(flags, f.Authentication.ToFlags()...)
	flags = append(flags, f.PostProcessing.ToFlags()...)
	flags = append(flags, f.SponsorBlock.ToFlags()...)
	flags = append(flags, f.Extractor.ToFlags()...)

	// Deduplicate flags by their ID, where only the last one is kept, and the others are deleted.
	for i := 0; i < len(flags); i++ {
		if flags[i].AllowsMultiple {
			continue
		}

		for j := i + 1; j < len(flags); j++ {
			if flags[j].AllowsMultiple {
				continue
			}

			if flags[i].ID == flags[j].ID {
				flags[j] = nil
				flags = append(flags[:j], flags[j+1:]...)
			}
		}
	}
	return flags
}

type FlagsGeneral struct {
	// Do not check for updates (default)
	NoUpdate *bool `json:"no_update,omitempty" id:"update_self" jsonschema:"title=NoUpdate" jsonschema_extras:"uid=update_self" jsonschema_description:"Do not check for updates (default)"`
	// Ignore download and postprocessing errors. The download will be considered successful even
	// if the postprocessing fails
	IgnoreErrors *bool `json:"ignore_errors,omitempty" id:"ignoreerrors" jsonschema:"title=IgnoreErrors" jsonschema_extras:"uid=ignoreerrors" jsonschema_description:"Ignore download and postprocessing errors. The download will be considered successful even if the postprocessing fails"`
	// Continue with next video on download errors; e.g. to skip unavailable videos in a playlist
	// (default)
	NoAbortOnError *bool `json:"no_abort_on_error,omitempty" id:"ignoreerrors" jsonschema:"title=NoAbortOnError" jsonschema_extras:"uid=ignoreerrors" jsonschema_description:"Continue with next video on download errors; e.g. to skip unavailable videos in a playlist (default)"`
	// Abort downloading of further videos if an error occurs
	AbortOnError *bool `json:"abort_on_error,omitempty" id:"ignoreerrors" jsonschema:"title=AbortOnError" jsonschema_extras:"uid=ignoreerrors" jsonschema_description:"Abort downloading of further videos if an error occurs"`
	// Extractor names to use separated by commas. You can also use regexes, "all", "default" and
	// "end" (end URL matching); e.g. --ies "holodex.*,end,youtube". Prefix the name with a "-"
	// to exclude it, e.g. --ies default,-generic. Use --list-extractors for a list of extractor
	// names.
	UseExtractors         *string `json:"use_extractors,omitempty" id:"allowed_extractors" jsonschema:"title=UseExtractors" jsonschema_extras:"uid=allowed_extractors" jsonschema_description:"Extractor names to use separated by commas. You can also use regexes, \"all\", \"default\" and \"end\" (end URL matching); e.g. --ies \"holodex.*,end,youtube\". Prefix the name with a \"-\" to exclude it, e.g. --ies default,-generic. Use --list-extractors for a list of extractor names."`
	ForceGenericExtractor *bool   `json:"force_generic_extractor,omitempty" id:"force_generic_extractor" jsonschema:"title=ForceGenericExtractor" jsonschema_extras:"uid=force_generic_extractor" jsonschema_description:""`
	// Use this prefix for unqualified URLs. E.g. "gvsearch2:python" downloads two videos from
	// google videos for the search term "python". Use the value "auto" to let yt-dlp guess
	// ("auto_warning" to emit a warning when guessing). "error" just throws an error. The
	// default value "fixup_error" repairs broken URLs, but emits an error if this is not
	// possible instead of searching
	DefaultSearch *string `json:"default_search,omitempty" id:"default_search" jsonschema:"title=DefaultSearch" jsonschema_extras:"uid=default_search" jsonschema_description:"Use this prefix for unqualified URLs. E.g. \"gvsearch2:python\" downloads two videos from google videos for the search term \"python\". Use the value \"auto\" to let yt-dlp guess (\"auto_warning\" to emit a warning when guessing). \"error\" just throws an error. The default value \"fixup_error\" repairs broken URLs, but emits an error if this is not possible instead of searching"`
	// Don't load any more configuration files except those given to --config-locations. For
	// backward compatibility, if this option is found inside the system configuration file, the
	// user configuration is not loaded.
	IgnoreConfig *bool `json:"ignore_config,omitempty" id:"ignoreconfig" jsonschema:"title=IgnoreConfig" jsonschema_extras:"uid=ignoreconfig" jsonschema_description:"Don't load any more configuration files except those given to --config-locations. For backward compatibility, if this option is found inside the system configuration file, the user configuration is not loaded."`
	// Do not load any custom configuration files (default). When given inside a configuration
	// file, ignore all previous --config-locations defined in the current file
	NoConfigLocations *bool `json:"no_config_locations,omitempty" id:"config_locations" jsonschema:"title=NoConfigLocations" jsonschema_extras:"uid=config_locations" jsonschema_description:"Do not load any custom configuration files (default). When given inside a configuration file, ignore all previous --config-locations defined in the current file"`
	// Location of the main configuration file; either the path to the config or its containing
	// directory ("-" for stdin). Can be used multiple times and inside other configuration files
	ConfigLocations []string `json:"config_locations,omitempty" id:"config_locations" jsonschema:"title=ConfigLocations" jsonschema_extras:"uid=config_locations" jsonschema_description:"Location of the main configuration file; either the path to the config or its containing directory (\"-\" for stdin). Can be used multiple times and inside other configuration files"`
	// Path to an additional directory to search for plugins. This option can be used multiple
	// times to add multiple directories. Use "default" to search the default plugin directories
	// (default)
	PluginDirs []string `json:"plugin_dirs,omitempty" id:"plugin_dirs" jsonschema:"title=PluginDirs" jsonschema_extras:"uid=plugin_dirs" jsonschema_description:"Path to an additional directory to search for plugins. This option can be used multiple times to add multiple directories. Use \"default\" to search the default plugin directories (default)"`
	// Clear plugin directories to search, including defaults and those provided by previous
	// --plugin-dirs
	NoPluginDirs *bool `json:"no_plugin_dirs,omitempty" id:"plugin_dirs" jsonschema:"title=NoPluginDirs" jsonschema_extras:"uid=plugin_dirs" jsonschema_description:"Clear plugin directories to search, including defaults and those provided by previous --plugin-dirs"`
	// Additional JavaScript runtime to enable, with an optional location for the runtime (either
	// the path to the binary or its containing directory). This option can be used multiple
	// times to enable multiple runtimes. Supported runtimes are (in order of priority, from
	// highest to lowest): deno, node, quickjs, bun. Only "deno" is enabled by default. The
	// highest priority runtime that is both enabled and available will be used. In order to use
	// a lower priority runtime when "deno" is available, --no-js-runtimes needs to be passed
	// before enabling other runtimes
	JsRuntimes []string `json:"js_runtimes,omitempty" id:"js_runtimes" jsonschema:"title=JsRuntimes" jsonschema_extras:"uid=js_runtimes" jsonschema_description:"Additional JavaScript runtime to enable, with an optional location for the runtime (either the path to the binary or its containing directory). This option can be used multiple times to enable multiple runtimes. Supported runtimes are (in order of priority, from highest to lowest): deno, node, quickjs, bun. Only \"deno\" is enabled by default. The highest priority runtime that is both enabled and available will be used. In order to use a lower priority runtime when \"deno\" is available, --no-js-runtimes needs to be passed before enabling other runtimes"`
	// Clear JavaScript runtimes to enable, including defaults and those provided by previous
	// --js-runtimes
	NoJsRuntimes *bool `json:"no_js_runtimes,omitempty" id:"js_runtimes" jsonschema:"title=NoJsRuntimes" jsonschema_extras:"uid=js_runtimes" jsonschema_description:"Clear JavaScript runtimes to enable, including defaults and those provided by previous --js-runtimes"`
	// Remote components to allow yt-dlp to fetch when required. This option is currently not
	// needed if you are using an official executable or have the requisite version of the
	// yt-dlp-ejs package installed. You can use this option multiple times to allow multiple
	// components. Supported values: ejs:npm (external JavaScript components from npm),
	// ejs:github (external JavaScript components from yt-dlp-ejs GitHub). By default, no remote
	// components are allowed
	RemoteComponents []string `json:"remote_components,omitempty" id:"remote_components" jsonschema:"title=RemoteComponents" jsonschema_extras:"uid=remote_components" jsonschema_description:"Remote components to allow yt-dlp to fetch when required. This option is currently not needed if you are using an official executable or have the requisite version of the yt-dlp-ejs package installed. You can use this option multiple times to allow multiple components. Supported values: ejs:npm (external JavaScript components from npm), ejs:github (external JavaScript components from yt-dlp-ejs GitHub). By default, no remote components are allowed"`
	// Disallow fetching of all remote components, including any previously allowed by
	// --remote-components or defaults.
	NoRemoteComponents *bool `json:"no_remote_components,omitempty" id:"remote_components" jsonschema:"title=NoRemoteComponents" jsonschema_extras:"uid=remote_components" jsonschema_description:"Disallow fetching of all remote components, including any previously allowed by --remote-components or defaults."`
	// Do not extract a playlist's URL result entries; some entry metadata may be missing and
	// downloading may be bypassed
	FlatPlaylist *bool `json:"flat_playlist,omitempty" id:"extract_flat" jsonschema:"title=FlatPlaylist" jsonschema_extras:"uid=extract_flat" jsonschema_description:"Do not extract a playlist's URL result entries; some entry metadata may be missing and downloading may be bypassed"`
	// Fully extract the videos of a playlist (default)
	NoFlatPlaylist *bool `json:"no_flat_playlist,omitempty" id:"extract_flat" jsonschema:"title=NoFlatPlaylist" jsonschema_extras:"uid=extract_flat" jsonschema_description:"Fully extract the videos of a playlist (default)"`
	// Download livestreams from the start. Currently experimental and only supported for YouTube
	// and Twitch
	LiveFromStart *bool `json:"live_from_start,omitempty" id:"live_from_start" jsonschema:"title=LiveFromStart" jsonschema_extras:"uid=live_from_start" jsonschema_description:"Download livestreams from the start. Currently experimental and only supported for YouTube and Twitch"`
	// Download livestreams from the current time (default)
	NoLiveFromStart *bool `json:"no_live_from_start,omitempty" id:"live_from_start" jsonschema:"title=NoLiveFromStart" jsonschema_extras:"uid=live_from_start" jsonschema_description:"Download livestreams from the current time (default)"`
	// Wait for scheduled streams to become available. Pass the minimum number of seconds (or
	// range) to wait between retries
	WaitForVideo *string `json:"wait_for_video,omitempty" id:"wait_for_video" jsonschema:"title=WaitForVideo" jsonschema_extras:"uid=wait_for_video" jsonschema_description:"Wait for scheduled streams to become available. Pass the minimum number of seconds (or range) to wait between retries"`
	// Do not wait for scheduled streams (default)
	NoWaitForVideo *bool `json:"no_wait_for_video,omitempty" id:"wait_for_video" jsonschema:"title=NoWaitForVideo" jsonschema_extras:"uid=wait_for_video" jsonschema_description:"Do not wait for scheduled streams (default)"`
	// Mark videos watched (even with --simulate)
	MarkWatched *bool `json:"mark_watched,omitempty" id:"mark_watched" jsonschema:"title=MarkWatched" jsonschema_extras:"uid=mark_watched" jsonschema_description:"Mark videos watched (even with --simulate)"`
	// Do not mark videos watched (default)
	NoMarkWatched *bool `json:"no_mark_watched,omitempty" id:"mark_watched" jsonschema:"title=NoMarkWatched" jsonschema_extras:"uid=mark_watched" jsonschema_description:"Do not mark videos watched (default)"`
	NoColors      *bool `json:"no_colors,omitempty" id:"color" jsonschema:"title=NoColors" jsonschema_extras:"uid=color" jsonschema_description:""`
	// Whether to emit color codes in output, optionally prefixed by the STREAM (stdout or
	// stderr) to apply the setting to. Can be one of "always", "auto" (default), "never", or
	// "no_color" (use non color terminal sequences). Use "auto-tty" or "no_color-tty" to decide
	// based on terminal support only. Can be used multiple times
	Color []string `json:"color,omitempty" id:"color" jsonschema:"title=Color" jsonschema_extras:"uid=color" jsonschema_description:"Whether to emit color codes in output, optionally prefixed by the STREAM (stdout or stderr) to apply the setting to. Can be one of \"always\", \"auto\" (default), \"never\", or \"no_color\" (use non color terminal sequences). Use \"auto-tty\" or \"no_color-tty\" to decide based on terminal support only. Can be used multiple times"`
	// Options that can help keep compatibility with youtube-dl or youtube-dlc configurations by
	// reverting some of the changes made in yt-dlp. See "Differences in default behavior" for
	// details
	CompatOptions *string `json:"compat_options,omitempty" id:"compat_opts" jsonschema:"title=CompatOptions" jsonschema_extras:"uid=compat_opts" jsonschema_description:"Options that can help keep compatibility with youtube-dl or youtube-dlc configurations by reverting some of the changes made in yt-dlp. See \"Differences in default behavior\" for details"`
	// Applies a predefined set of options. e.g. --preset-alias mp3. The following presets are
	// available: mp3, aac, mp4, mkv, sleep. See the "Preset Aliases" section at the end for more
	// info. This option can be used multiple times
	PresetAlias []string `json:"preset_alias,omitempty" id:"preset-alias" jsonschema:"title=PresetAlias" jsonschema_extras:"uid=preset-alias" jsonschema_description:"Applies a predefined set of options. e.g. --preset-alias mp3. The following presets are available: mp3, aac, mp4, mkv, sleep. See the \"Preset Aliases\" section at the end for more info. This option can be used multiple times"`
}

// Validate ensures all flags have appropriate values. If there are validation-specific
// errors, they will be returned as a [ErrMultipleJSONParsingFlags] error.
func (g *FlagsGeneral) Validate() error {
	if g == nil {
		return nil
	}

	var validationErrs []*ErrJSONParsingFlag

	duplicates := g.ToFlags().Duplicates()
	for _, duplicate := range duplicates {
		validationErrs = append(validationErrs, &ErrJSONParsingFlag{
			JSONPath: "general." + duplicate.ID,
			Flag:     duplicate.Flag,
			ID:       duplicate.ID,
			Err:      fmt.Errorf("duplicate flag (with conflicting ID %q) found: %v", duplicate.ID, duplicate.Flag),
		})
	}

	if len(validationErrs) > 0 {
		return &ErrMultipleJSONParsingFlags{Errors: validationErrs}
	}
	return nil
}

// ToFlags returns the generated flags based off the provided configuration. [FlagsGeneral.Validate]
// should be called first.
func (g *FlagsGeneral) ToFlags() (flags Flags) {
	if g == nil {
		return flags
	}
	if g.NoUpdate != nil && *g.NoUpdate {
		flags = append(flags, &Flag{ID: "update_self", Flag: "--no-update", Args: nil})
	}
	if g.IgnoreErrors != nil && *g.IgnoreErrors {
		flags = append(flags, &Flag{ID: "ignoreerrors", Flag: "--ignore-errors", Args: nil})
	}
	if g.NoAbortOnError != nil && *g.NoAbortOnError {
		flags = append(flags, &Flag{ID: "ignoreerrors", Flag: "--no-abort-on-error", Args: nil})
	}
	if g.AbortOnError != nil && *g.AbortOnError {
		flags = append(flags, &Flag{ID: "ignoreerrors", Flag: "--abort-on-error", Args: nil})
	}
	if g.UseExtractors != nil {
		flags = append(flags, &Flag{ID: "allowed_extractors", Flag: "--use-extractors", Args: []any{*g.UseExtractors}})
	}
	if g.ForceGenericExtractor != nil && *g.ForceGenericExtractor {
		flags = append(flags, &Flag{ID: "force_generic_extractor", Flag: "--force-generic-extractor", Args: nil})
	}
	if g.DefaultSearch != nil {
		flags = append(flags, &Flag{ID: "default_search", Flag: "--default-search", Args: []any{*g.DefaultSearch}})
	}
	if g.IgnoreConfig != nil && *g.IgnoreConfig {
		flags = append(flags, &Flag{ID: "ignoreconfig", Flag: "--ignore-config", Args: nil})
	}
	if g.NoConfigLocations != nil && *g.NoConfigLocations {
		flags = append(flags, &Flag{ID: "config_locations", Flag: "--no-config-locations", Args: nil})
	}
	for _, v := range g.ConfigLocations {
		flags = append(flags, &Flag{ID: "config_locations", Flag: "--config-locations", AllowsMultiple: true, Args: []any{v}})
	}
	for _, v := range g.PluginDirs {
		flags = append(flags, &Flag{ID: "plugin_dirs", Flag: "--plugin-dirs", AllowsMultiple: true, Args: []any{v}})
	}
	if g.NoPluginDirs != nil && *g.NoPluginDirs {
		flags = append(flags, &Flag{ID: "plugin_dirs", Flag: "--no-plugin-dirs", Args: nil})
	}
	for _, v := range g.JsRuntimes {
		flags = append(flags, &Flag{ID: "js_runtimes", Flag: "--js-runtimes", AllowsMultiple: true, Args: []any{v}})
	}
	if g.NoJsRuntimes != nil && *g.NoJsRuntimes {
		flags = append(flags, &Flag{ID: "js_runtimes", Flag: "--no-js-runtimes", Args: nil})
	}
	for _, v := range g.RemoteComponents {
		flags = append(flags, &Flag{ID: "remote_components", Flag: "--remote-components", AllowsMultiple: true, Args: []any{v}})
	}
	if g.NoRemoteComponents != nil && *g.NoRemoteComponents {
		flags = append(flags, &Flag{ID: "remote_components", Flag: "--no-remote-components", Args: nil})
	}
	if g.FlatPlaylist != nil && *g.FlatPlaylist {
		flags = append(flags, &Flag{ID: "extract_flat", Flag: "--flat-playlist", Args: nil})
	}
	if g.NoFlatPlaylist != nil && *g.NoFlatPlaylist {
		flags = append(flags, &Flag{ID: "extract_flat", Flag: "--no-flat-playlist", Args: nil})
	}
	if g.LiveFromStart != nil && *g.LiveFromStart {
		flags = append(flags, &Flag{ID: "live_from_start", Flag: "--live-from-start", Args: nil})
	}
	if g.NoLiveFromStart != nil && *g.NoLiveFromStart {
		flags = append(flags, &Flag{ID: "live_from_start", Flag: "--no-live-from-start", Args: nil})
	}
	if g.WaitForVideo != nil {
		flags = append(flags, &Flag{ID: "wait_for_video", Flag: "--wait-for-video", Args: []any{*g.WaitForVideo}})
	}
	if g.NoWaitForVideo != nil && *g.NoWaitForVideo {
		flags = append(flags, &Flag{ID: "wait_for_video", Flag: "--no-wait-for-video", Args: nil})
	}
	if g.MarkWatched != nil && *g.MarkWatched {
		flags = append(flags, &Flag{ID: "mark_watched", Flag: "--mark-watched", Args: nil})
	}
	if g.NoMarkWatched != nil && *g.NoMarkWatched {
		flags = append(flags, &Flag{ID: "mark_watched", Flag: "--no-mark-watched", Args: nil})
	}
	if g.NoColors != nil && *g.NoColors {
		flags = append(flags, &Flag{ID: "color", Flag: "--no-colors", Args: nil})
	}
	for _, v := range g.Color {
		flags = append(flags, &Flag{ID: "color", Flag: "--color", AllowsMultiple: true, Args: []any{v}})
	}
	if g.CompatOptions != nil {
		flags = append(flags, &Flag{ID: "compat_opts", Flag: "--compat-options", Args: []any{*g.CompatOptions}})
	}
	for _, v := range g.PresetAlias {
		flags = append(flags, &Flag{ID: "preset-alias", Flag: "--preset-alias", AllowsMultiple: true, Args: []any{v}})
	}
	return flags
}

type FlagsNetwork struct {
	// Use the specified HTTP/HTTPS/SOCKS proxy. To enable SOCKS proxy, specify a proper scheme,
	// e.g. socks5://user:pass@127.0.0.1:1080/. Pass in an empty string (--proxy "") for direct
	// connection
	Proxy *string `json:"proxy,omitempty" id:"proxy" jsonschema:"title=Proxy" jsonschema_extras:"uid=proxy" jsonschema_description:"Use the specified HTTP/HTTPS/SOCKS proxy. To enable SOCKS proxy, specify a proper scheme, e.g. socks5://user:pass@127.0.0.1:1080/. Pass in an empty string (--proxy \"\") for direct connection"`
	// Time to wait before giving up, in seconds
	SocketTimeout *float64 `json:"socket_timeout,omitempty" id:"socket_timeout" jsonschema:"title=SocketTimeout" jsonschema_extras:"uid=socket_timeout" jsonschema_description:"Time to wait before giving up, in seconds"`
	// Client-side IP address to bind to
	SourceAddress *string `json:"source_address,omitempty" id:"source_address" jsonschema:"title=SourceAddress" jsonschema_extras:"uid=source_address" jsonschema_description:"Client-side IP address to bind to"`
	// Client to impersonate for requests. E.g. chrome, chrome-110, chrome:windows-10. Pass
	// --impersonate="" to impersonate any client. Note that forcing impersonation for all
	// requests may have a detrimental impact on download speed and stability
	Impersonate *string `json:"impersonate,omitempty" id:"impersonate" jsonschema:"title=Impersonate" jsonschema_extras:"uid=impersonate" jsonschema_description:"Client to impersonate for requests. E.g. chrome, chrome-110, chrome:windows-10. Pass --impersonate=\"\" to impersonate any client. Note that forcing impersonation for all requests may have a detrimental impact on download speed and stability"`
	// List available clients to impersonate.
	ListImpersonateTargets *bool `json:"list_impersonate_targets,omitempty" id:"list_impersonate_targets" jsonschema:"title=ListImpersonateTargets" jsonschema_extras:"uid=list_impersonate_targets" jsonschema_description:"List available clients to impersonate."`
	// Make all connections via IPv4
	ForceIPv4 *bool `json:"force_ipv_4,omitempty" id:"source_address" jsonschema:"title=ForceIPv4" jsonschema_extras:"uid=source_address" jsonschema_description:"Make all connections via IPv4"`
	// Make all connections via IPv6
	ForceIPv6 *bool `json:"force_ipv_6,omitempty" id:"source_address" jsonschema:"title=ForceIPv6" jsonschema_extras:"uid=source_address" jsonschema_description:"Make all connections via IPv6"`
	// Enable file:// URLs. This is disabled by default for security reasons.
	EnableFileURLs *bool `json:"enable_file_urls,omitempty" id:"enable_file_urls" jsonschema:"title=EnableFileURLs" jsonschema_extras:"uid=enable_file_urls" jsonschema_description:"Enable file:// URLs. This is disabled by default for security reasons."`
}

// Validate ensures all flags have appropriate values. If there are validation-specific
// errors, they will be returned as a [ErrMultipleJSONParsingFlags] error.
func (g *FlagsNetwork) Validate() error {
	if g == nil {
		return nil
	}

	var validationErrs []*ErrJSONParsingFlag

	duplicates := g.ToFlags().Duplicates()
	for _, duplicate := range duplicates {
		validationErrs = append(validationErrs, &ErrJSONParsingFlag{
			JSONPath: "network." + duplicate.ID,
			Flag:     duplicate.Flag,
			ID:       duplicate.ID,
			Err:      fmt.Errorf("duplicate flag (with conflicting ID %q) found: %v", duplicate.ID, duplicate.Flag),
		})
	}

	if len(validationErrs) > 0 {
		return &ErrMultipleJSONParsingFlags{Errors: validationErrs}
	}
	return nil
}

// ToFlags returns the generated flags based off the provided configuration. [FlagsNetwork.Validate]
// should be called first.
func (g *FlagsNetwork) ToFlags() (flags Flags) {
	if g == nil {
		return flags
	}
	if g.Proxy != nil {
		flags = append(flags, &Flag{ID: "proxy", Flag: "--proxy", Args: []any{*g.Proxy}})
	}
	if g.SocketTimeout != nil {
		flags = append(flags, &Flag{ID: "socket_timeout", Flag: "--socket-timeout", Args: []any{*g.SocketTimeout}})
	}
	if g.SourceAddress != nil {
		flags = append(flags, &Flag{ID: "source_address", Flag: "--source-address", Args: []any{*g.SourceAddress}})
	}
	if g.Impersonate != nil {
		flags = append(flags, &Flag{ID: "impersonate", Flag: "--impersonate", Args: []any{*g.Impersonate}})
	}
	if g.ListImpersonateTargets != nil && *g.ListImpersonateTargets {
		flags = append(flags, &Flag{ID: "list_impersonate_targets", Flag: "--list-impersonate-targets", Args: nil})
	}
	if g.ForceIPv4 != nil && *g.ForceIPv4 {
		flags = append(flags, &Flag{ID: "source_address", Flag: "--force-ipv4", Args: nil})
	}
	if g.ForceIPv6 != nil && *g.ForceIPv6 {
		flags = append(flags, &Flag{ID: "source_address", Flag: "--force-ipv6", Args: nil})
	}
	if g.EnableFileURLs != nil && *g.EnableFileURLs {
		flags = append(flags, &Flag{ID: "enable_file_urls", Flag: "--enable-file-urls", Args: nil})
	}
	return flags
}

type FlagsGeoRestriction struct {
	// Use this proxy to verify the IP address for some geo-restricted sites. The default proxy
	// specified by --proxy (or none, if the option is not present) is used for the actual
	// downloading
	GeoVerificationProxy *string `json:"geo_verification_proxy,omitempty" id:"geo_verification_proxy" jsonschema:"title=GeoVerificationProxy" jsonschema_extras:"uid=geo_verification_proxy" jsonschema_description:"Use this proxy to verify the IP address for some geo-restricted sites. The default proxy specified by --proxy (or none, if the option is not present) is used for the actual downloading"`
	// How to fake X-Forwarded-For HTTP header to try bypassing geographic restriction. One of
	// "default" (only when known to be useful), "never", an IP block in CIDR notation, or a
	// two-letter ISO 3166-2 country code
	XFF              *string `json:"xff,omitempty" id:"geo_bypass" jsonschema:"title=XFF" jsonschema_extras:"uid=geo_bypass" jsonschema_description:"How to fake X-Forwarded-For HTTP header to try bypassing geographic restriction. One of \"default\" (only when known to be useful), \"never\", an IP block in CIDR notation, or a two-letter ISO 3166-2 country code"`
	GeoBypass        *bool   `json:"geo_bypass,omitempty" id:"geo_bypass" jsonschema:"title=GeoBypass" jsonschema_extras:"uid=geo_bypass" jsonschema_description:""`
	NoGeoBypass      *bool   `json:"no_geo_bypass,omitempty" id:"geo_bypass" jsonschema:"title=NoGeoBypass" jsonschema_extras:"uid=geo_bypass" jsonschema_description:""`
	GeoBypassCountry *string `json:"geo_bypass_country,omitempty" id:"geo_bypass" jsonschema:"title=GeoBypassCountry" jsonschema_extras:"uid=geo_bypass" jsonschema_description:""`
	GeoBypassIPBlock *string `json:"geo_bypass_ip_block,omitempty" id:"geo_bypass" jsonschema:"title=GeoBypassIPBlock" jsonschema_extras:"uid=geo_bypass" jsonschema_description:""`
}

// Validate ensures all flags have appropriate values. If there are validation-specific
// errors, they will be returned as a [ErrMultipleJSONParsingFlags] error.
func (g *FlagsGeoRestriction) Validate() error {
	if g == nil {
		return nil
	}

	var validationErrs []*ErrJSONParsingFlag

	duplicates := g.ToFlags().Duplicates()
	for _, duplicate := range duplicates {
		validationErrs = append(validationErrs, &ErrJSONParsingFlag{
			JSONPath: "geo_restriction." + duplicate.ID,
			Flag:     duplicate.Flag,
			ID:       duplicate.ID,
			Err:      fmt.Errorf("duplicate flag (with conflicting ID %q) found: %v", duplicate.ID, duplicate.Flag),
		})
	}

	if len(validationErrs) > 0 {
		return &ErrMultipleJSONParsingFlags{Errors: validationErrs}
	}
	return nil
}

// ToFlags returns the generated flags based off the provided configuration. [FlagsGeoRestriction.Validate]
// should be called first.
func (g *FlagsGeoRestriction) ToFlags() (flags Flags) {
	if g == nil {
		return flags
	}
	if g.GeoVerificationProxy != nil {
		flags = append(flags, &Flag{ID: "geo_verification_proxy", Flag: "--geo-verification-proxy", Args: []any{*g.GeoVerificationProxy}})
	}
	if g.XFF != nil {
		flags = append(flags, &Flag{ID: "geo_bypass", Flag: "--xff", Args: []any{*g.XFF}})
	}
	if g.GeoBypass != nil && *g.GeoBypass {
		flags = append(flags, &Flag{ID: "geo_bypass", Flag: "--geo-bypass", Args: nil})
	}
	if g.NoGeoBypass != nil && *g.NoGeoBypass {
		flags = append(flags, &Flag{ID: "geo_bypass", Flag: "--no-geo-bypass", Args: nil})
	}
	if g.GeoBypassCountry != nil {
		flags = append(flags, &Flag{ID: "geo_bypass", Flag: "--geo-bypass-country", Args: []any{*g.GeoBypassCountry}})
	}
	if g.GeoBypassIPBlock != nil {
		flags = append(flags, &Flag{ID: "geo_bypass", Flag: "--geo-bypass-ip-block", Args: []any{*g.GeoBypassIPBlock}})
	}
	return flags
}

type FlagsVideoSelection struct {
	PlaylistStart *int `json:"playlist_start,omitempty" id:"playliststart" jsonschema:"title=PlaylistStart" jsonschema_extras:"uid=playliststart" jsonschema_description:""`
	PlaylistEnd   *int `json:"playlist_end,omitempty" id:"playlistend" jsonschema:"title=PlaylistEnd" jsonschema_extras:"uid=playlistend" jsonschema_description:""`
	// Comma-separated playlist_index of the items to download. You can specify a range using
	// "[START]:[STOP][:STEP]". For backward compatibility, START-STOP is also supported. Use
	// negative indices to count from the right and negative STEP to download in reverse order.
	// E.g. "-I 1:3,7,-5::2" used on a playlist of size 15 will download the items at index
	// 1,2,3,7,11,13,15
	PlaylistItems *string `json:"playlist_items,omitempty" id:"playlist_items" jsonschema:"title=PlaylistItems" jsonschema_extras:"uid=playlist_items" jsonschema_description:"Comma-separated playlist_index of the items to download. You can specify a range using \"[START]:[STOP][:STEP]\". For backward compatibility, START-STOP is also supported. Use negative indices to count from the right and negative STEP to download in reverse order. E.g. \"-I 1:3,7,-5::2\" used on a playlist of size 15 will download the items at index 1,2,3,7,11,13,15"`
	MatchTitle    *string `json:"match_title,omitempty" id:"matchtitle" jsonschema:"title=MatchTitle" jsonschema_extras:"uid=matchtitle" jsonschema_description:""`
	RejectTitle   *string `json:"reject_title,omitempty" id:"rejecttitle" jsonschema:"title=RejectTitle" jsonschema_extras:"uid=rejecttitle" jsonschema_description:""`
	// Abort download if filesize is smaller than SIZE, e.g. 50k or 44.6M
	MinFileSize *string `json:"min_filesize,omitempty" id:"min_filesize" jsonschema:"title=MinFileSize" jsonschema_extras:"uid=min_filesize" jsonschema_description:"Abort download if filesize is smaller than SIZE, e.g. 50k or 44.6M"`
	// Abort download if filesize is larger than SIZE, e.g. 50k or 44.6M
	MaxFileSize *string `json:"max_filesize,omitempty" id:"max_filesize" jsonschema:"title=MaxFileSize" jsonschema_extras:"uid=max_filesize" jsonschema_description:"Abort download if filesize is larger than SIZE, e.g. 50k or 44.6M"`
	// Download only videos uploaded on this date. The date can be "YYYYMMDD" or in the format
	// [now|today|yesterday][-N[day|week|month|year]]. E.g. "--date today-2weeks" downloads only
	// videos uploaded on the same day two weeks ago
	Date *string `json:"date,omitempty" id:"date" jsonschema:"title=Date" jsonschema_extras:"uid=date" jsonschema_description:"Download only videos uploaded on this date. The date can be \"YYYYMMDD\" or in the format [now|today|yesterday][-N[day|week|month|year]]. E.g. \"--date today-2weeks\" downloads only videos uploaded on the same day two weeks ago"`
	// Download only videos uploaded on or before this date. The date formats accepted are the
	// same as --date
	DateBefore *string `json:"datebefore,omitempty" id:"datebefore" jsonschema:"title=DateBefore" jsonschema_extras:"uid=datebefore" jsonschema_description:"Download only videos uploaded on or before this date. The date formats accepted are the same as --date"`
	// Download only videos uploaded on or after this date. The date formats accepted are the
	// same as --date
	DateAfter *string `json:"dateafter,omitempty" id:"dateafter" jsonschema:"title=DateAfter" jsonschema_extras:"uid=dateafter" jsonschema_description:"Download only videos uploaded on or after this date. The date formats accepted are the same as --date"`
	MinViews  *int    `json:"min_views,omitempty" id:"min_views" jsonschema:"title=MinViews" jsonschema_extras:"uid=min_views" jsonschema_description:""`
	MaxViews  *int    `json:"max_views,omitempty" id:"max_views" jsonschema:"title=MaxViews" jsonschema_extras:"uid=max_views" jsonschema_description:""`
	// Generic video filter. Any "OUTPUT TEMPLATE" field can be compared with a number or a
	// string using the operators defined in "Filtering Formats". You can also simply specify a
	// field to match if the field is present, use "!field" to check if the field is not present,
	// and "&" to check multiple conditions. Use a "\" to escape "&" or quotes if needed. If used
	// multiple times, the filter matches if at least one of the conditions is met. E.g.
	// --match-filters !is_live --match-filters "like_count>?100 & description~='(?i)\bcats \&
	// dogs\b'" matches only videos that are not live OR those that have a like count more than
	// 100 (or the like field is not available) and also has a description that contains the
	// phrase "cats & dogs" (caseless). Use "--match-filters -" to interactively ask whether to
	// download each video
	MatchFilters []string `json:"match_filters,omitempty" id:"match_filter" jsonschema:"title=MatchFilters" jsonschema_extras:"uid=match_filter" jsonschema_description:"Generic video filter. Any \"OUTPUT TEMPLATE\" field can be compared with a number or a string using the operators defined in \"Filtering Formats\". You can also simply specify a field to match if the field is present, use \"!field\" to check if the field is not present, and \"&\" to check multiple conditions. Use a \"\\\" to escape \"&\" or quotes if needed. If used multiple times, the filter matches if at least one of the conditions is met. E.g. --match-filters !is_live --match-filters \"like_count>?100 & description~='(?i)\\bcats \\& dogs\\b'\" matches only videos that are not live OR those that have a like count more than 100 (or the like field is not available) and also has a description that contains the phrase \"cats & dogs\" (caseless). Use \"--match-filters -\" to interactively ask whether to download each video"`
	// Do not use any --match-filters (default)
	NoMatchFilters *bool `json:"no_match_filters,omitempty" id:"match_filter" jsonschema:"title=NoMatchFilters" jsonschema_extras:"uid=match_filter" jsonschema_description:"Do not use any --match-filters (default)"`
	// Same as "--match-filters" but stops the download process when a video is rejected
	BreakMatchFilters *string `json:"break_match_filters,omitempty" id:"breaking_match_filter" jsonschema:"title=BreakMatchFilters" jsonschema_extras:"uid=breaking_match_filter" jsonschema_description:"Same as \"--match-filters\" but stops the download process when a video is rejected"`
	// Do not use any --break-match-filters (default)
	NoBreakMatchFilters *bool `json:"no_break_match_filters,omitempty" id:"breaking_match_filter" jsonschema:"title=NoBreakMatchFilters" jsonschema_extras:"uid=breaking_match_filter" jsonschema_description:"Do not use any --break-match-filters (default)"`
	// Download only the video, if the URL refers to a video and a playlist
	NoPlaylist *bool `json:"no_playlist,omitempty" id:"noplaylist" jsonschema:"title=NoPlaylist" jsonschema_extras:"uid=noplaylist" jsonschema_description:"Download only the video, if the URL refers to a video and a playlist"`
	// Download the playlist, if the URL refers to a video and a playlist
	YesPlaylist *bool `json:"yes_playlist,omitempty" id:"noplaylist" jsonschema:"title=YesPlaylist" jsonschema_extras:"uid=noplaylist" jsonschema_description:"Download the playlist, if the URL refers to a video and a playlist"`
	// Download only videos suitable for the given age
	AgeLimit *int `json:"age_limit,omitempty" id:"age_limit" jsonschema:"title=AgeLimit" jsonschema_extras:"uid=age_limit" jsonschema_description:"Download only videos suitable for the given age"`
	// Download only videos not listed in the archive file. Record the IDs of all downloaded
	// videos in it
	DownloadArchive *string `json:"download_archive,omitempty" id:"download_archive" jsonschema:"title=DownloadArchive" jsonschema_extras:"uid=download_archive" jsonschema_description:"Download only videos not listed in the archive file. Record the IDs of all downloaded videos in it"`
	// Do not use archive file (default)
	NoDownloadArchive *bool `json:"no_download_archive,omitempty" id:"download_archive" jsonschema:"title=NoDownloadArchive" jsonschema_extras:"uid=download_archive" jsonschema_description:"Do not use archive file (default)"`
	// Abort after downloading NUMBER files
	MaxDownloads *int `json:"max_downloads,omitempty" id:"max_downloads" jsonschema:"title=MaxDownloads" jsonschema_extras:"uid=max_downloads" jsonschema_description:"Abort after downloading NUMBER files"`
	// Stop the download process when encountering a file that is in the archive supplied with
	// the --download-archive option
	BreakOnExisting *bool `json:"break_on_existing,omitempty" id:"break_on_existing" jsonschema:"title=BreakOnExisting" jsonschema_extras:"uid=break_on_existing" jsonschema_description:"Stop the download process when encountering a file that is in the archive supplied with the --download-archive option"`
	// Do not stop the download process when encountering a file that is in the archive (default)
	NoBreakOnExisting *bool `json:"no_break_on_existing,omitempty" id:"break_on_existing" jsonschema:"title=NoBreakOnExisting" jsonschema_extras:"uid=break_on_existing" jsonschema_description:"Do not stop the download process when encountering a file that is in the archive (default)"`
	BreakOnReject     *bool `json:"break_on_reject,omitempty" id:"break_on_reject" jsonschema:"title=BreakOnReject" jsonschema_extras:"uid=break_on_reject" jsonschema_description:""`
	// Alters --max-downloads, --break-on-existing, --break-match-filters, and autonumber to
	// reset per input URL
	BreakPerInput *bool `json:"break_per_input,omitempty" id:"break_per_url" jsonschema:"title=BreakPerInput" jsonschema_extras:"uid=break_per_url" jsonschema_description:"Alters --max-downloads, --break-on-existing, --break-match-filters, and autonumber to reset per input URL"`
	// --break-on-existing and similar options terminates the entire download queue
	NoBreakPerInput *bool `json:"no_break_per_input,omitempty" id:"break_per_url" jsonschema:"title=NoBreakPerInput" jsonschema_extras:"uid=break_per_url" jsonschema_description:"--break-on-existing and similar options terminates the entire download queue"`
	// Number of allowed failures until the rest of the playlist is skipped
	SkipPlaylistAfterErrors *int `json:"skip_playlist_after_errors,omitempty" id:"skip_playlist_after_errors" jsonschema:"title=SkipPlaylistAfterErrors" jsonschema_extras:"uid=skip_playlist_after_errors" jsonschema_description:"Number of allowed failures until the rest of the playlist is skipped"`
}

// Validate ensures all flags have appropriate values. If there are validation-specific
// errors, they will be returned as a [ErrMultipleJSONParsingFlags] error.
func (g *FlagsVideoSelection) Validate() error {
	if g == nil {
		return nil
	}

	var validationErrs []*ErrJSONParsingFlag

	duplicates := g.ToFlags().Duplicates()
	for _, duplicate := range duplicates {
		validationErrs = append(validationErrs, &ErrJSONParsingFlag{
			JSONPath: "video_selection." + duplicate.ID,
			Flag:     duplicate.Flag,
			ID:       duplicate.ID,
			Err:      fmt.Errorf("duplicate flag (with conflicting ID %q) found: %v", duplicate.ID, duplicate.Flag),
		})
	}

	if len(validationErrs) > 0 {
		return &ErrMultipleJSONParsingFlags{Errors: validationErrs}
	}
	return nil
}

// ToFlags returns the generated flags based off the provided configuration. [FlagsVideoSelection.Validate]
// should be called first.
func (g *FlagsVideoSelection) ToFlags() (flags Flags) {
	if g == nil {
		return flags
	}
	if g.PlaylistStart != nil {
		flags = append(flags, &Flag{ID: "playliststart", Flag: "--playlist-start", Args: []any{*g.PlaylistStart}})
	}
	if g.PlaylistEnd != nil {
		flags = append(flags, &Flag{ID: "playlistend", Flag: "--playlist-end", Args: []any{*g.PlaylistEnd}})
	}
	if g.PlaylistItems != nil {
		flags = append(flags, &Flag{ID: "playlist_items", Flag: "--playlist-items", Args: []any{*g.PlaylistItems}})
	}
	if g.MatchTitle != nil {
		flags = append(flags, &Flag{ID: "matchtitle", Flag: "--match-title", Args: []any{*g.MatchTitle}})
	}
	if g.RejectTitle != nil {
		flags = append(flags, &Flag{ID: "rejecttitle", Flag: "--reject-title", Args: []any{*g.RejectTitle}})
	}
	if g.MinFileSize != nil {
		flags = append(flags, &Flag{ID: "min_filesize", Flag: "--min-filesize", Args: []any{*g.MinFileSize}})
	}
	if g.MaxFileSize != nil {
		flags = append(flags, &Flag{ID: "max_filesize", Flag: "--max-filesize", Args: []any{*g.MaxFileSize}})
	}
	if g.Date != nil {
		flags = append(flags, &Flag{ID: "date", Flag: "--date", Args: []any{*g.Date}})
	}
	if g.DateBefore != nil {
		flags = append(flags, &Flag{ID: "datebefore", Flag: "--datebefore", Args: []any{*g.DateBefore}})
	}
	if g.DateAfter != nil {
		flags = append(flags, &Flag{ID: "dateafter", Flag: "--dateafter", Args: []any{*g.DateAfter}})
	}
	if g.MinViews != nil {
		flags = append(flags, &Flag{ID: "min_views", Flag: "--min-views", Args: []any{*g.MinViews}})
	}
	if g.MaxViews != nil {
		flags = append(flags, &Flag{ID: "max_views", Flag: "--max-views", Args: []any{*g.MaxViews}})
	}
	for _, v := range g.MatchFilters {
		flags = append(flags, &Flag{ID: "match_filter", Flag: "--match-filters", AllowsMultiple: true, Args: []any{v}})
	}
	if g.NoMatchFilters != nil && *g.NoMatchFilters {
		flags = append(flags, &Flag{ID: "match_filter", Flag: "--no-match-filters", Args: nil})
	}
	if g.BreakMatchFilters != nil {
		flags = append(flags, &Flag{ID: "breaking_match_filter", Flag: "--break-match-filters", Args: []any{*g.BreakMatchFilters}})
	}
	if g.NoBreakMatchFilters != nil && *g.NoBreakMatchFilters {
		flags = append(flags, &Flag{ID: "breaking_match_filter", Flag: "--no-break-match-filters", Args: nil})
	}
	if g.NoPlaylist != nil && *g.NoPlaylist {
		flags = append(flags, &Flag{ID: "noplaylist", Flag: "--no-playlist", Args: nil})
	}
	if g.YesPlaylist != nil && *g.YesPlaylist {
		flags = append(flags, &Flag{ID: "noplaylist", Flag: "--yes-playlist", Args: nil})
	}
	if g.AgeLimit != nil {
		flags = append(flags, &Flag{ID: "age_limit", Flag: "--age-limit", Args: []any{*g.AgeLimit}})
	}
	if g.DownloadArchive != nil {
		flags = append(flags, &Flag{ID: "download_archive", Flag: "--download-archive", Args: []any{*g.DownloadArchive}})
	}
	if g.NoDownloadArchive != nil && *g.NoDownloadArchive {
		flags = append(flags, &Flag{ID: "download_archive", Flag: "--no-download-archive", Args: nil})
	}
	if g.MaxDownloads != nil {
		flags = append(flags, &Flag{ID: "max_downloads", Flag: "--max-downloads", Args: []any{*g.MaxDownloads}})
	}
	if g.BreakOnExisting != nil && *g.BreakOnExisting {
		flags = append(flags, &Flag{ID: "break_on_existing", Flag: "--break-on-existing", Args: nil})
	}
	if g.NoBreakOnExisting != nil && *g.NoBreakOnExisting {
		flags = append(flags, &Flag{ID: "break_on_existing", Flag: "--no-break-on-existing", Args: nil})
	}
	if g.BreakOnReject != nil && *g.BreakOnReject {
		flags = append(flags, &Flag{ID: "break_on_reject", Flag: "--break-on-reject", Args: nil})
	}
	if g.BreakPerInput != nil && *g.BreakPerInput {
		flags = append(flags, &Flag{ID: "break_per_url", Flag: "--break-per-input", Args: nil})
	}
	if g.NoBreakPerInput != nil && *g.NoBreakPerInput {
		flags = append(flags, &Flag{ID: "break_per_url", Flag: "--no-break-per-input", Args: nil})
	}
	if g.SkipPlaylistAfterErrors != nil {
		flags = append(flags, &Flag{ID: "skip_playlist_after_errors", Flag: "--skip-playlist-after-errors", Args: []any{*g.SkipPlaylistAfterErrors}})
	}
	return flags
}

type FlagsDownload struct {
	// Number of fragments of a dash/hlsnative video that should be downloaded concurrently
	// (default is 1)
	ConcurrentFragments *int `json:"concurrent_fragments,omitempty" id:"concurrent_fragment_downloads" jsonschema:"title=ConcurrentFragments" jsonschema_extras:"uid=concurrent_fragment_downloads" jsonschema_description:"Number of fragments of a dash/hlsnative video that should be downloaded concurrently (default is 1)"`
	// Maximum download rate in bytes per second, e.g. 50K or 4.2M
	LimitRate *string `json:"limit_rate,omitempty" id:"ratelimit" jsonschema:"title=LimitRate" jsonschema_extras:"uid=ratelimit" jsonschema_description:"Maximum download rate in bytes per second, e.g. 50K or 4.2M"`
	// Minimum download rate in bytes per second below which throttling is assumed and the video
	// data is re-extracted, e.g. 100K
	ThrottledRate *string `json:"throttled_rate,omitempty" id:"throttledratelimit" jsonschema:"title=ThrottledRate" jsonschema_extras:"uid=throttledratelimit" jsonschema_description:"Minimum download rate in bytes per second below which throttling is assumed and the video data is re-extracted, e.g. 100K"`
	// Number of retries (default is 10), or "infinite"
	Retries *string `json:"retries,omitempty" id:"retries" jsonschema:"title=Retries" jsonschema_extras:"uid=retries" jsonschema_description:"Number of retries (default is 10), or \"infinite\""`
	// Number of times to retry on file access error (default is 3), or "infinite"
	FileAccessRetries *string `json:"file_access_retries,omitempty" id:"file_access_retries" jsonschema:"title=FileAccessRetries" jsonschema_extras:"uid=file_access_retries" jsonschema_description:"Number of times to retry on file access error (default is 3), or \"infinite\""`
	// Number of retries for a fragment (default is 10), or "infinite" (DASH, hlsnative and ISM)
	FragmentRetries *string `json:"fragment_retries,omitempty" id:"fragment_retries" jsonschema:"title=FragmentRetries" jsonschema_extras:"uid=fragment_retries" jsonschema_description:"Number of retries for a fragment (default is 10), or \"infinite\" (DASH, hlsnative and ISM)"`
	// Time to sleep between retries in seconds (optionally) prefixed by the type of retry (http
	// (default), fragment, file_access, extractor) to apply the sleep to. EXPR can be a number,
	// linear=START[:END[:STEP=1]] or exp=START[:END[:BASE=2]]. This option can be used multiple
	// times to set the sleep for the different retry types, e.g. --retry-sleep linear=1::2
	// --retry-sleep fragment:exp=1:20
	RetrySleep []string `json:"retry_sleep,omitempty" id:"retry_sleep" jsonschema:"title=RetrySleep" jsonschema_extras:"uid=retry_sleep" jsonschema_description:"Time to sleep between retries in seconds (optionally) prefixed by the type of retry (http (default), fragment, file_access, extractor) to apply the sleep to. EXPR can be a number, linear=START[:END[:STEP=1]] or exp=START[:END[:BASE=2]]. This option can be used multiple times to set the sleep for the different retry types, e.g. --retry-sleep linear=1::2 --retry-sleep fragment:exp=1:20"`
	// Skip unavailable fragments for DASH, hlsnative and ISM downloads (default)
	SkipUnavailableFragments *bool `json:"skip_unavailable_fragments,omitempty" id:"skip_unavailable_fragments" jsonschema:"title=SkipUnavailableFragments" jsonschema_extras:"uid=skip_unavailable_fragments" jsonschema_description:"Skip unavailable fragments for DASH, hlsnative and ISM downloads (default)"`
	// Abort download if a fragment is unavailable
	AbortOnUnavailableFragments *bool `json:"abort_on_unavailable_fragments,omitempty" id:"skip_unavailable_fragments" jsonschema:"title=AbortOnUnavailableFragments" jsonschema_extras:"uid=skip_unavailable_fragments" jsonschema_description:"Abort download if a fragment is unavailable"`
	// Keep downloaded fragments on disk after downloading is finished
	KeepFragments *bool `json:"keep_fragments,omitempty" id:"keep_fragments" jsonschema:"title=KeepFragments" jsonschema_extras:"uid=keep_fragments" jsonschema_description:"Keep downloaded fragments on disk after downloading is finished"`
	// Delete downloaded fragments after downloading is finished (default)
	NoKeepFragments *bool `json:"no_keep_fragments,omitempty" id:"keep_fragments" jsonschema:"title=NoKeepFragments" jsonschema_extras:"uid=keep_fragments" jsonschema_description:"Delete downloaded fragments after downloading is finished (default)"`
	// Size of download buffer, e.g. 1024 or 16K (default is 1024)
	BufferSize *string `json:"buffer_size,omitempty" id:"buffersize" jsonschema:"title=BufferSize" jsonschema_extras:"uid=buffersize" jsonschema_description:"Size of download buffer, e.g. 1024 or 16K (default is 1024)"`
	// The buffer size is automatically resized from an initial value of --buffer-size (default)
	ResizeBuffer *bool `json:"resize_buffer,omitempty" id:"noresizebuffer" jsonschema:"title=ResizeBuffer" jsonschema_extras:"uid=noresizebuffer" jsonschema_description:"The buffer size is automatically resized from an initial value of --buffer-size (default)"`
	// Do not automatically adjust the buffer size
	NoResizeBuffer *bool `json:"no_resize_buffer,omitempty" id:"noresizebuffer" jsonschema:"title=NoResizeBuffer" jsonschema_extras:"uid=noresizebuffer" jsonschema_description:"Do not automatically adjust the buffer size"`
	// Size of a chunk for chunk-based HTTP downloading, e.g. 10485760 or 10M (default is
	// disabled). May be useful for bypassing bandwidth throttling imposed by a webserver
	// (experimental)
	HTTPChunkSize     *string `json:"http_chunk_size,omitempty" id:"http_chunk_size" jsonschema:"title=HTTPChunkSize" jsonschema_extras:"uid=http_chunk_size" jsonschema_description:"Size of a chunk for chunk-based HTTP downloading, e.g. 10485760 or 10M (default is disabled). May be useful for bypassing bandwidth throttling imposed by a webserver (experimental)"`
	PlaylistReverse   *bool   `json:"playlist_reverse,omitempty" id:"playlist_reverse" jsonschema:"title=PlaylistReverse" jsonschema_extras:"uid=playlist_reverse" jsonschema_description:""`
	NoPlaylistReverse *bool   `json:"no_playlist_reverse,omitempty" id:"playlist_reverse" jsonschema:"title=NoPlaylistReverse" jsonschema_extras:"uid=playlist_reverse" jsonschema_description:""`
	// Download playlist videos in random order
	PlaylistRandom *bool `json:"playlist_random,omitempty" id:"playlist_random" jsonschema:"title=PlaylistRandom" jsonschema_extras:"uid=playlist_random" jsonschema_description:"Download playlist videos in random order"`
	// Process entries in the playlist as they are received. This disables n_entries,
	// --playlist-random and --playlist-reverse
	LazyPlaylist *bool `json:"lazy_playlist,omitempty" id:"lazy_playlist" jsonschema:"title=LazyPlaylist" jsonschema_extras:"uid=lazy_playlist" jsonschema_description:"Process entries in the playlist as they are received. This disables n_entries, --playlist-random and --playlist-reverse"`
	// Process videos in the playlist only after the entire playlist is parsed (default)
	NoLazyPlaylist  *bool `json:"no_lazy_playlist,omitempty" id:"lazy_playlist" jsonschema:"title=NoLazyPlaylist" jsonschema_extras:"uid=lazy_playlist" jsonschema_description:"Process videos in the playlist only after the entire playlist is parsed (default)"`
	HLSPreferNative *bool `json:"hls_prefer_native,omitempty" id:"hls_prefer_native" jsonschema:"title=HLSPreferNative" jsonschema_extras:"uid=hls_prefer_native" jsonschema_description:""`
	HLSPreferFFmpeg *bool `json:"hls_prefer_ffmpeg,omitempty" id:"hls_prefer_native" jsonschema:"title=HLSPreferFFmpeg" jsonschema_extras:"uid=hls_prefer_native" jsonschema_description:""`
	// Use the mpegts container for HLS videos; allowing some players to play the video while
	// downloading, and reducing the chance of file corruption if download is interrupted. This
	// is enabled by default for live streams
	HLSUseMPEGTS *bool `json:"hls_use_mpegts,omitempty" id:"hls_use_mpegts" jsonschema:"title=HLSUseMPEGTS" jsonschema_extras:"uid=hls_use_mpegts" jsonschema_description:"Use the mpegts container for HLS videos; allowing some players to play the video while downloading, and reducing the chance of file corruption if download is interrupted. This is enabled by default for live streams"`
	// Do not use the mpegts container for HLS videos. This is default when not downloading live
	// streams
	NoHLSUseMPEGTS *bool `json:"no_hls_use_mpegts,omitempty" id:"hls_use_mpegts" jsonschema:"title=NoHLSUseMPEGTS" jsonschema_extras:"uid=hls_use_mpegts" jsonschema_description:"Do not use the mpegts container for HLS videos. This is default when not downloading live streams"`
	// Download only chapters that match the regular expression. A "*" prefix denotes time-range
	// instead of chapter. Negative timestamps are calculated from the end. "*from-url" can be
	// used to download between the "start_time" and "end_time" extracted from the URL. Needs
	// ffmpeg. This option can be used multiple times to download multiple sections, e.g.
	// --download-sections "*10:15-inf" --download-sections "intro"
	DownloadSections []string `json:"download_sections,omitempty" id:"download_ranges" jsonschema:"title=DownloadSections" jsonschema_extras:"uid=download_ranges" jsonschema_description:"Download only chapters that match the regular expression. A \"*\" prefix denotes time-range instead of chapter. Negative timestamps are calculated from the end. \"*from-url\" can be used to download between the \"start_time\" and \"end_time\" extracted from the URL. Needs ffmpeg. This option can be used multiple times to download multiple sections, e.g. --download-sections \"*10:15-inf\" --download-sections \"intro\""`
	// Name or path of the external downloader to use (optionally) prefixed by the protocols
	// (http, ftp, m3u8, dash, rstp, rtmp, mms) to use it for. Currently supports native, aria2c,
	// axel, curl, ffmpeg, httpie, wget. You can use this option multiple times to set different
	// downloaders for different protocols. E.g. --downloader aria2c --downloader
	// "dash,m3u8:native" will use aria2c for http/ftp downloads, and the native downloader for
	// dash/m3u8 downloads
	Downloader []string `json:"downloader,omitempty" id:"external_downloader" jsonschema:"title=Downloader" jsonschema_extras:"uid=external_downloader" jsonschema_description:"Name or path of the external downloader to use (optionally) prefixed by the protocols (http, ftp, m3u8, dash, rstp, rtmp, mms) to use it for. Currently supports native, aria2c, axel, curl, ffmpeg, httpie, wget. You can use this option multiple times to set different downloaders for different protocols. E.g. --downloader aria2c --downloader \"dash,m3u8:native\" will use aria2c for http/ftp downloads, and the native downloader for dash/m3u8 downloads"`
	// Give these arguments to the external downloader. Specify the downloader name and the
	// arguments separated by a colon ":". For ffmpeg, arguments can be passed to different
	// positions using the same syntax as --postprocessor-args. You can use this option multiple
	// times to give different arguments to different downloaders
	DownloaderArgs []string `json:"downloader_args,omitempty" id:"external_downloader_args" jsonschema:"title=DownloaderArgs" jsonschema_extras:"uid=external_downloader_args" jsonschema_description:"Give these arguments to the external downloader. Specify the downloader name and the arguments separated by a colon \":\". For ffmpeg, arguments can be passed to different positions using the same syntax as --postprocessor-args. You can use this option multiple times to give different arguments to different downloaders"`
}

// Validate ensures all flags have appropriate values. If there are validation-specific
// errors, they will be returned as a [ErrMultipleJSONParsingFlags] error.
func (g *FlagsDownload) Validate() error {
	if g == nil {
		return nil
	}

	var validationErrs []*ErrJSONParsingFlag

	duplicates := g.ToFlags().Duplicates()
	for _, duplicate := range duplicates {
		validationErrs = append(validationErrs, &ErrJSONParsingFlag{
			JSONPath: "download." + duplicate.ID,
			Flag:     duplicate.Flag,
			ID:       duplicate.ID,
			Err:      fmt.Errorf("duplicate flag (with conflicting ID %q) found: %v", duplicate.ID, duplicate.Flag),
		})
	}

	if len(validationErrs) > 0 {
		return &ErrMultipleJSONParsingFlags{Errors: validationErrs}
	}
	return nil
}

// ToFlags returns the generated flags based off the provided configuration. [FlagsDownload.Validate]
// should be called first.
func (g *FlagsDownload) ToFlags() (flags Flags) {
	if g == nil {
		return flags
	}
	if g.ConcurrentFragments != nil {
		flags = append(flags, &Flag{ID: "concurrent_fragment_downloads", Flag: "--concurrent-fragments", Args: []any{*g.ConcurrentFragments}})
	}
	if g.LimitRate != nil {
		flags = append(flags, &Flag{ID: "ratelimit", Flag: "--limit-rate", Args: []any{*g.LimitRate}})
	}
	if g.ThrottledRate != nil {
		flags = append(flags, &Flag{ID: "throttledratelimit", Flag: "--throttled-rate", Args: []any{*g.ThrottledRate}})
	}
	if g.Retries != nil {
		flags = append(flags, &Flag{ID: "retries", Flag: "--retries", Args: []any{*g.Retries}})
	}
	if g.FileAccessRetries != nil {
		flags = append(flags, &Flag{ID: "file_access_retries", Flag: "--file-access-retries", Args: []any{*g.FileAccessRetries}})
	}
	if g.FragmentRetries != nil {
		flags = append(flags, &Flag{ID: "fragment_retries", Flag: "--fragment-retries", Args: []any{*g.FragmentRetries}})
	}
	for _, v := range g.RetrySleep {
		flags = append(flags, &Flag{ID: "retry_sleep", Flag: "--retry-sleep", AllowsMultiple: true, Args: []any{v}})
	}
	if g.SkipUnavailableFragments != nil && *g.SkipUnavailableFragments {
		flags = append(flags, &Flag{ID: "skip_unavailable_fragments", Flag: "--skip-unavailable-fragments", Args: nil})
	}
	if g.AbortOnUnavailableFragments != nil && *g.AbortOnUnavailableFragments {
		flags = append(flags, &Flag{ID: "skip_unavailable_fragments", Flag: "--abort-on-unavailable-fragments", Args: nil})
	}
	if g.KeepFragments != nil && *g.KeepFragments {
		flags = append(flags, &Flag{ID: "keep_fragments", Flag: "--keep-fragments", Args: nil})
	}
	if g.NoKeepFragments != nil && *g.NoKeepFragments {
		flags = append(flags, &Flag{ID: "keep_fragments", Flag: "--no-keep-fragments", Args: nil})
	}
	if g.BufferSize != nil {
		flags = append(flags, &Flag{ID: "buffersize", Flag: "--buffer-size", Args: []any{*g.BufferSize}})
	}
	if g.ResizeBuffer != nil && *g.ResizeBuffer {
		flags = append(flags, &Flag{ID: "noresizebuffer", Flag: "--resize-buffer", Args: nil})
	}
	if g.NoResizeBuffer != nil && *g.NoResizeBuffer {
		flags = append(flags, &Flag{ID: "noresizebuffer", Flag: "--no-resize-buffer", Args: nil})
	}
	if g.HTTPChunkSize != nil {
		flags = append(flags, &Flag{ID: "http_chunk_size", Flag: "--http-chunk-size", Args: []any{*g.HTTPChunkSize}})
	}
	if g.PlaylistReverse != nil && *g.PlaylistReverse {
		flags = append(flags, &Flag{ID: "playlist_reverse", Flag: "--playlist-reverse", Args: nil})
	}
	if g.NoPlaylistReverse != nil && *g.NoPlaylistReverse {
		flags = append(flags, &Flag{ID: "playlist_reverse", Flag: "--no-playlist-reverse", Args: nil})
	}
	if g.PlaylistRandom != nil && *g.PlaylistRandom {
		flags = append(flags, &Flag{ID: "playlist_random", Flag: "--playlist-random", Args: nil})
	}
	if g.LazyPlaylist != nil && *g.LazyPlaylist {
		flags = append(flags, &Flag{ID: "lazy_playlist", Flag: "--lazy-playlist", Args: nil})
	}
	if g.NoLazyPlaylist != nil && *g.NoLazyPlaylist {
		flags = append(flags, &Flag{ID: "lazy_playlist", Flag: "--no-lazy-playlist", Args: nil})
	}
	if g.HLSPreferNative != nil && *g.HLSPreferNative {
		flags = append(flags, &Flag{ID: "hls_prefer_native", Flag: "--hls-prefer-native", Args: nil})
	}
	if g.HLSPreferFFmpeg != nil && *g.HLSPreferFFmpeg {
		flags = append(flags, &Flag{ID: "hls_prefer_native", Flag: "--hls-prefer-ffmpeg", Args: nil})
	}
	if g.HLSUseMPEGTS != nil && *g.HLSUseMPEGTS {
		flags = append(flags, &Flag{ID: "hls_use_mpegts", Flag: "--hls-use-mpegts", Args: nil})
	}
	if g.NoHLSUseMPEGTS != nil && *g.NoHLSUseMPEGTS {
		flags = append(flags, &Flag{ID: "hls_use_mpegts", Flag: "--no-hls-use-mpegts", Args: nil})
	}
	for _, v := range g.DownloadSections {
		flags = append(flags, &Flag{ID: "download_ranges", Flag: "--download-sections", AllowsMultiple: true, Args: []any{v}})
	}
	for _, v := range g.Downloader {
		flags = append(flags, &Flag{ID: "external_downloader", Flag: "--downloader", AllowsMultiple: true, Args: []any{v}})
	}
	for _, v := range g.DownloaderArgs {
		flags = append(flags, &Flag{ID: "external_downloader_args", Flag: "--downloader-args", AllowsMultiple: true, Args: []any{v}})
	}
	return flags
}

type FlagsFilesystem struct {
	// File containing URLs to download ("-" for stdin), one URL per line. Lines starting with
	// "#", ";" or "]" are considered as comments and ignored
	BatchFile *string `json:"batch_file,omitempty" id:"batchfile" jsonschema:"title=BatchFile" jsonschema_extras:"uid=batchfile" jsonschema_description:"File containing URLs to download (\"-\" for stdin), one URL per line. Lines starting with \"#\", \";\" or \"]\" are considered as comments and ignored"`
	// Do not read URLs from batch file (default)
	NoBatchFile *bool `json:"no_batch_file,omitempty" id:"batchfile" jsonschema:"title=NoBatchFile" jsonschema_extras:"uid=batchfile" jsonschema_description:"Do not read URLs from batch file (default)"`
	ID          *bool `json:"id,omitempty" id:"useid" jsonschema:"title=ID" jsonschema_extras:"uid=useid" jsonschema_description:""`
	// The paths where the files should be downloaded. Specify the type of file and the path
	// separated by a colon ":". All the same TYPES as --output are supported. Additionally, you
	// can also provide "home" (default) and "temp" paths. All intermediary files are first
	// downloaded to the temp path and then the final files are moved over to the home path after
	// download is finished. This option is ignored if --output is an absolute path
	Paths *string `json:"paths,omitempty" id:"paths" jsonschema:"title=Paths" jsonschema_extras:"uid=paths" jsonschema_description:"The paths where the files should be downloaded. Specify the type of file and the path separated by a colon \":\". All the same TYPES as --output are supported. Additionally, you can also provide \"home\" (default) and \"temp\" paths. All intermediary files are first downloaded to the temp path and then the final files are moved over to the home path after download is finished. This option is ignored if --output is an absolute path"`
	// Output filename template; see "OUTPUT TEMPLATE" for details
	Output *string `json:"output,omitempty" id:"outtmpl" jsonschema:"title=Output" jsonschema_extras:"uid=outtmpl" jsonschema_description:"Output filename template; see \"OUTPUT TEMPLATE\" for details"`
	// Placeholder for unavailable fields in --output (default: "NA")
	OutputNaPlaceholder *string `json:"output_na_placeholder,omitempty" id:"outtmpl_na_placeholder" jsonschema:"title=OutputNaPlaceholder" jsonschema_extras:"uid=outtmpl_na_placeholder" jsonschema_description:"Placeholder for unavailable fields in --output (default: \"NA\")"`
	AutoNumberSize      *int    `json:"autonumber_size,omitempty" id:"autonumber_size" jsonschema:"title=AutoNumberSize" jsonschema_extras:"uid=autonumber_size" jsonschema_description:""`
	AutoNumberStart     *int    `json:"autonumber_start,omitempty" id:"autonumber_start" jsonschema:"title=AutoNumberStart" jsonschema_extras:"uid=autonumber_start" jsonschema_description:""`
	// Restrict filenames to only ASCII characters, and avoid "&" and spaces in filenames
	RestrictFilenames *bool `json:"restrict_filenames,omitempty" id:"restrictfilenames" jsonschema:"title=RestrictFilenames" jsonschema_extras:"uid=restrictfilenames" jsonschema_description:"Restrict filenames to only ASCII characters, and avoid \"&\" and spaces in filenames"`
	// Allow Unicode characters, "&" and spaces in filenames (default)
	NoRestrictFilenames *bool `json:"no_restrict_filenames,omitempty" id:"restrictfilenames" jsonschema:"title=NoRestrictFilenames" jsonschema_extras:"uid=restrictfilenames" jsonschema_description:"Allow Unicode characters, \"&\" and spaces in filenames (default)"`
	// Force filenames to be Windows-compatible
	WindowsFilenames *bool `json:"windows_filenames,omitempty" id:"windowsfilenames" jsonschema:"title=WindowsFilenames" jsonschema_extras:"uid=windowsfilenames" jsonschema_description:"Force filenames to be Windows-compatible"`
	// Sanitize filenames only minimally
	NoWindowsFilenames *bool `json:"no_windows_filenames,omitempty" id:"windowsfilenames" jsonschema:"title=NoWindowsFilenames" jsonschema_extras:"uid=windowsfilenames" jsonschema_description:"Sanitize filenames only minimally"`
	// Limit the filename length (excluding extension) to the specified number of characters
	TrimFilenames *int `json:"trim_filenames,omitempty" id:"trim_file_name" jsonschema:"title=TrimFilenames" jsonschema_extras:"uid=trim_file_name" jsonschema_description:"Limit the filename length (excluding extension) to the specified number of characters"`
	// Do not overwrite any files
	NoOverwrites *bool `json:"no_overwrites,omitempty" id:"overwrites" jsonschema:"title=NoOverwrites" jsonschema_extras:"uid=overwrites" jsonschema_description:"Do not overwrite any files"`
	// Overwrite all video and metadata files. This option includes --no-continue
	ForceOverwrites *bool `json:"force_overwrites,omitempty" id:"overwrites" jsonschema:"title=ForceOverwrites" jsonschema_extras:"uid=overwrites" jsonschema_description:"Overwrite all video and metadata files. This option includes --no-continue"`
	// Do not overwrite the video, but overwrite related files (default)
	NoForceOverwrites *bool `json:"no_force_overwrites,omitempty" id:"overwrites" jsonschema:"title=NoForceOverwrites" jsonschema_extras:"uid=overwrites" jsonschema_description:"Do not overwrite the video, but overwrite related files (default)"`
	// Resume partially downloaded files/fragments (default)
	Continue *bool `json:"continue,omitempty" id:"continue_dl" jsonschema:"title=Continue" jsonschema_extras:"uid=continue_dl" jsonschema_description:"Resume partially downloaded files/fragments (default)"`
	// Do not resume partially downloaded fragments. If the file is not fragmented, restart
	// download of the entire file
	NoContinue *bool `json:"no_continue,omitempty" id:"continue_dl" jsonschema:"title=NoContinue" jsonschema_extras:"uid=continue_dl" jsonschema_description:"Do not resume partially downloaded fragments. If the file is not fragmented, restart download of the entire file"`
	// Use .part files instead of writing directly into output file (default)
	Part *bool `json:"part,omitempty" id:"nopart" jsonschema:"title=Part" jsonschema_extras:"uid=nopart" jsonschema_description:"Use .part files instead of writing directly into output file (default)"`
	// Do not use .part files - write directly into output file
	NoPart *bool `json:"no_part,omitempty" id:"nopart" jsonschema:"title=NoPart" jsonschema_extras:"uid=nopart" jsonschema_description:"Do not use .part files - write directly into output file"`
	// Use the Last-modified header to set the file modification time
	Mtime *bool `json:"mtime,omitempty" id:"updatetime" jsonschema:"title=Mtime" jsonschema_extras:"uid=updatetime" jsonschema_description:"Use the Last-modified header to set the file modification time"`
	// Do not use the Last-modified header to set the file modification time (default)
	NoMtime *bool `json:"no_mtime,omitempty" id:"updatetime" jsonschema:"title=NoMtime" jsonschema_extras:"uid=updatetime" jsonschema_description:"Do not use the Last-modified header to set the file modification time (default)"`
	// Write video description to a .description file
	WriteDescription *bool `json:"write_description,omitempty" id:"writedescription" jsonschema:"title=WriteDescription" jsonschema_extras:"uid=writedescription" jsonschema_description:"Write video description to a .description file"`
	// Do not write video description (default)
	NoWriteDescription *bool `json:"no_write_description,omitempty" id:"writedescription" jsonschema:"title=NoWriteDescription" jsonschema_extras:"uid=writedescription" jsonschema_description:"Do not write video description (default)"`
	// Write video metadata to a .info.json file (this may contain personal information)
	WriteInfoJSON *bool `json:"write_info_json,omitempty" id:"writeinfojson" jsonschema:"title=WriteInfoJSON" jsonschema_extras:"uid=writeinfojson" jsonschema_description:"Write video metadata to a .info.json file (this may contain personal information)"`
	// Do not write video metadata (default)
	NoWriteInfoJSON *bool `json:"no_write_info_json,omitempty" id:"writeinfojson" jsonschema:"title=NoWriteInfoJSON" jsonschema_extras:"uid=writeinfojson" jsonschema_description:"Do not write video metadata (default)"`
	// Write playlist metadata in addition to the video metadata when using --write-info-json,
	// --write-description etc. (default)
	WritePlaylistMetafiles *bool `json:"write_playlist_metafiles,omitempty" id:"allow_playlist_files" jsonschema:"title=WritePlaylistMetafiles" jsonschema_extras:"uid=allow_playlist_files" jsonschema_description:"Write playlist metadata in addition to the video metadata when using --write-info-json, --write-description etc. (default)"`
	// Do not write playlist metadata when using --write-info-json, --write-description etc.
	NoWritePlaylistMetafiles *bool `json:"no_write_playlist_metafiles,omitempty" id:"allow_playlist_files" jsonschema:"title=NoWritePlaylistMetafiles" jsonschema_extras:"uid=allow_playlist_files" jsonschema_description:"Do not write playlist metadata when using --write-info-json, --write-description etc."`
	// Remove some internal metadata such as filenames from the infojson (default)
	CleanInfoJSON *bool `json:"clean_info_json,omitempty" id:"clean_infojson" jsonschema:"title=CleanInfoJSON" jsonschema_extras:"uid=clean_infojson" jsonschema_description:"Remove some internal metadata such as filenames from the infojson (default)"`
	// Write all fields to the infojson
	NoCleanInfoJSON *bool `json:"no_clean_info_json,omitempty" id:"clean_infojson" jsonschema:"title=NoCleanInfoJSON" jsonschema_extras:"uid=clean_infojson" jsonschema_description:"Write all fields to the infojson"`
	// Retrieve video comments to be placed in the infojson. The comments are fetched even
	// without this option if the extraction is known to be quick
	WriteComments *bool `json:"write_comments,omitempty" id:"getcomments" jsonschema:"title=WriteComments" jsonschema_extras:"uid=getcomments" jsonschema_description:"Retrieve video comments to be placed in the infojson. The comments are fetched even without this option if the extraction is known to be quick"`
	// Do not retrieve video comments unless the extraction is known to be quick
	NoWriteComments *bool `json:"no_write_comments,omitempty" id:"getcomments" jsonschema:"title=NoWriteComments" jsonschema_extras:"uid=getcomments" jsonschema_description:"Do not retrieve video comments unless the extraction is known to be quick"`
	// JSON file containing the video information (created with the "--write-info-json" option)
	LoadInfoJSON *string `json:"load_info_json,omitempty" id:"load_info_filename" jsonschema:"title=LoadInfoJSON" jsonschema_extras:"uid=load_info_filename" jsonschema_description:"JSON file containing the video information (created with the \"--write-info-json\" option)"`
	// Netscape formatted file to read cookies from and dump cookie jar in
	Cookies *string `json:"cookies,omitempty" id:"cookiefile" jsonschema:"title=Cookies" jsonschema_extras:"uid=cookiefile" jsonschema_description:"Netscape formatted file to read cookies from and dump cookie jar in"`
	// Do not read/dump cookies from/to file (default)
	NoCookies *bool `json:"no_cookies,omitempty" id:"cookiefile" jsonschema:"title=NoCookies" jsonschema_extras:"uid=cookiefile" jsonschema_description:"Do not read/dump cookies from/to file (default)"`
	// The name of the browser to load cookies from. Currently supported browsers are: brave,
	// chrome, chromium, edge, firefox, opera, safari, vivaldi, whale. Optionally, the KEYRING
	// used for decrypting Chromium cookies on Linux, the name/path of the PROFILE to load
	// cookies from, and the CONTAINER name (if Firefox) ("none" for no container) can be given
	// with their respective separators. By default, all containers of the most recently accessed
	// profile are used. Currently supported keyrings are: basictext, gnomekeyring, kwallet,
	// kwallet5, kwallet6
	CookiesFromBrowser *string `json:"cookies_from_browser,omitempty" id:"cookiesfrombrowser" jsonschema:"title=CookiesFromBrowser" jsonschema_extras:"uid=cookiesfrombrowser" jsonschema_description:"The name of the browser to load cookies from. Currently supported browsers are: brave, chrome, chromium, edge, firefox, opera, safari, vivaldi, whale. Optionally, the KEYRING used for decrypting Chromium cookies on Linux, the name/path of the PROFILE to load cookies from, and the CONTAINER name (if Firefox) (\"none\" for no container) can be given with their respective separators. By default, all containers of the most recently accessed profile are used. Currently supported keyrings are: basictext, gnomekeyring, kwallet, kwallet5, kwallet6"`
	// Do not load cookies from browser (default)
	NoCookiesFromBrowser *bool `json:"no_cookies_from_browser,omitempty" id:"cookiesfrombrowser" jsonschema:"title=NoCookiesFromBrowser" jsonschema_extras:"uid=cookiesfrombrowser" jsonschema_description:"Do not load cookies from browser (default)"`
	// Location in the filesystem where yt-dlp can store some downloaded information (such as
	// client ids and signatures) permanently. By default ${XDG_CACHE_HOME}/yt-dlp
	CacheDir *string `json:"cache_dir,omitempty" id:"cachedir" jsonschema:"title=CacheDir" jsonschema_extras:"uid=cachedir" jsonschema_description:"Location in the filesystem where yt-dlp can store some downloaded information (such as client ids and signatures) permanently. By default ${XDG_CACHE_HOME}/yt-dlp"`
	// Disable filesystem caching
	NoCacheDir *bool `json:"no_cache_dir,omitempty" id:"cachedir" jsonschema:"title=NoCacheDir" jsonschema_extras:"uid=cachedir" jsonschema_description:"Disable filesystem caching"`
	// Delete all filesystem cache files
	RmCacheDir *bool `json:"rm_cache_dir,omitempty" id:"rm_cachedir" jsonschema:"title=RmCacheDir" jsonschema_extras:"uid=rm_cachedir" jsonschema_description:"Delete all filesystem cache files"`
}

// Validate ensures all flags have appropriate values. If there are validation-specific
// errors, they will be returned as a [ErrMultipleJSONParsingFlags] error.
func (g *FlagsFilesystem) Validate() error {
	if g == nil {
		return nil
	}

	var validationErrs []*ErrJSONParsingFlag

	duplicates := g.ToFlags().Duplicates()
	for _, duplicate := range duplicates {
		validationErrs = append(validationErrs, &ErrJSONParsingFlag{
			JSONPath: "filesystem." + duplicate.ID,
			Flag:     duplicate.Flag,
			ID:       duplicate.ID,
			Err:      fmt.Errorf("duplicate flag (with conflicting ID %q) found: %v", duplicate.ID, duplicate.Flag),
		})
	}

	if len(validationErrs) > 0 {
		return &ErrMultipleJSONParsingFlags{Errors: validationErrs}
	}
	return nil
}

// ToFlags returns the generated flags based off the provided configuration. [FlagsFilesystem.Validate]
// should be called first.
func (g *FlagsFilesystem) ToFlags() (flags Flags) {
	if g == nil {
		return flags
	}
	if g.BatchFile != nil {
		flags = append(flags, &Flag{ID: "batchfile", Flag: "--batch-file", Args: []any{*g.BatchFile}})
	}
	if g.NoBatchFile != nil && *g.NoBatchFile {
		flags = append(flags, &Flag{ID: "batchfile", Flag: "--no-batch-file", Args: nil})
	}
	if g.ID != nil && *g.ID {
		flags = append(flags, &Flag{ID: "useid", Flag: "--id", Args: nil})
	}
	if g.Paths != nil {
		flags = append(flags, &Flag{ID: "paths", Flag: "--paths", Args: []any{*g.Paths}})
	}
	if g.Output != nil {
		flags = append(flags, &Flag{ID: "outtmpl", Flag: "--output", Args: []any{*g.Output}})
	}
	if g.OutputNaPlaceholder != nil {
		flags = append(flags, &Flag{ID: "outtmpl_na_placeholder", Flag: "--output-na-placeholder", Args: []any{*g.OutputNaPlaceholder}})
	}
	if g.AutoNumberSize != nil {
		flags = append(flags, &Flag{ID: "autonumber_size", Flag: "--autonumber-size", Args: []any{*g.AutoNumberSize}})
	}
	if g.AutoNumberStart != nil {
		flags = append(flags, &Flag{ID: "autonumber_start", Flag: "--autonumber-start", Args: []any{*g.AutoNumberStart}})
	}
	if g.RestrictFilenames != nil && *g.RestrictFilenames {
		flags = append(flags, &Flag{ID: "restrictfilenames", Flag: "--restrict-filenames", Args: nil})
	}
	if g.NoRestrictFilenames != nil && *g.NoRestrictFilenames {
		flags = append(flags, &Flag{ID: "restrictfilenames", Flag: "--no-restrict-filenames", Args: nil})
	}
	if g.WindowsFilenames != nil && *g.WindowsFilenames {
		flags = append(flags, &Flag{ID: "windowsfilenames", Flag: "--windows-filenames", Args: nil})
	}
	if g.NoWindowsFilenames != nil && *g.NoWindowsFilenames {
		flags = append(flags, &Flag{ID: "windowsfilenames", Flag: "--no-windows-filenames", Args: nil})
	}
	if g.TrimFilenames != nil {
		flags = append(flags, &Flag{ID: "trim_file_name", Flag: "--trim-filenames", Args: []any{*g.TrimFilenames}})
	}
	if g.NoOverwrites != nil && *g.NoOverwrites {
		flags = append(flags, &Flag{ID: "overwrites", Flag: "--no-overwrites", Args: nil})
	}
	if g.ForceOverwrites != nil && *g.ForceOverwrites {
		flags = append(flags, &Flag{ID: "overwrites", Flag: "--force-overwrites", Args: nil})
	}
	if g.NoForceOverwrites != nil && *g.NoForceOverwrites {
		flags = append(flags, &Flag{ID: "overwrites", Flag: "--no-force-overwrites", Args: nil})
	}
	if g.Continue != nil && *g.Continue {
		flags = append(flags, &Flag{ID: "continue_dl", Flag: "--continue", Args: nil})
	}
	if g.NoContinue != nil && *g.NoContinue {
		flags = append(flags, &Flag{ID: "continue_dl", Flag: "--no-continue", Args: nil})
	}
	if g.Part != nil && *g.Part {
		flags = append(flags, &Flag{ID: "nopart", Flag: "--part", Args: nil})
	}
	if g.NoPart != nil && *g.NoPart {
		flags = append(flags, &Flag{ID: "nopart", Flag: "--no-part", Args: nil})
	}
	if g.Mtime != nil && *g.Mtime {
		flags = append(flags, &Flag{ID: "updatetime", Flag: "--mtime", Args: nil})
	}
	if g.NoMtime != nil && *g.NoMtime {
		flags = append(flags, &Flag{ID: "updatetime", Flag: "--no-mtime", Args: nil})
	}
	if g.WriteDescription != nil && *g.WriteDescription {
		flags = append(flags, &Flag{ID: "writedescription", Flag: "--write-description", Args: nil})
	}
	if g.NoWriteDescription != nil && *g.NoWriteDescription {
		flags = append(flags, &Flag{ID: "writedescription", Flag: "--no-write-description", Args: nil})
	}
	if g.WriteInfoJSON != nil && *g.WriteInfoJSON {
		flags = append(flags, &Flag{ID: "writeinfojson", Flag: "--write-info-json", Args: nil})
	}
	if g.NoWriteInfoJSON != nil && *g.NoWriteInfoJSON {
		flags = append(flags, &Flag{ID: "writeinfojson", Flag: "--no-write-info-json", Args: nil})
	}
	if g.WritePlaylistMetafiles != nil && *g.WritePlaylistMetafiles {
		flags = append(flags, &Flag{ID: "allow_playlist_files", Flag: "--write-playlist-metafiles", Args: nil})
	}
	if g.NoWritePlaylistMetafiles != nil && *g.NoWritePlaylistMetafiles {
		flags = append(flags, &Flag{ID: "allow_playlist_files", Flag: "--no-write-playlist-metafiles", Args: nil})
	}
	if g.CleanInfoJSON != nil && *g.CleanInfoJSON {
		flags = append(flags, &Flag{ID: "clean_infojson", Flag: "--clean-info-json", Args: nil})
	}
	if g.NoCleanInfoJSON != nil && *g.NoCleanInfoJSON {
		flags = append(flags, &Flag{ID: "clean_infojson", Flag: "--no-clean-info-json", Args: nil})
	}
	if g.WriteComments != nil && *g.WriteComments {
		flags = append(flags, &Flag{ID: "getcomments", Flag: "--write-comments", Args: nil})
	}
	if g.NoWriteComments != nil && *g.NoWriteComments {
		flags = append(flags, &Flag{ID: "getcomments", Flag: "--no-write-comments", Args: nil})
	}
	if g.LoadInfoJSON != nil {
		flags = append(flags, &Flag{ID: "load_info_filename", Flag: "--load-info-json", Args: []any{*g.LoadInfoJSON}})
	}
	if g.Cookies != nil {
		flags = append(flags, &Flag{ID: "cookiefile", Flag: "--cookies", Args: []any{*g.Cookies}})
	}
	if g.NoCookies != nil && *g.NoCookies {
		flags = append(flags, &Flag{ID: "cookiefile", Flag: "--no-cookies", Args: nil})
	}
	if g.CookiesFromBrowser != nil {
		flags = append(flags, &Flag{ID: "cookiesfrombrowser", Flag: "--cookies-from-browser", Args: []any{*g.CookiesFromBrowser}})
	}
	if g.NoCookiesFromBrowser != nil && *g.NoCookiesFromBrowser {
		flags = append(flags, &Flag{ID: "cookiesfrombrowser", Flag: "--no-cookies-from-browser", Args: nil})
	}
	if g.CacheDir != nil {
		flags = append(flags, &Flag{ID: "cachedir", Flag: "--cache-dir", Args: []any{*g.CacheDir}})
	}
	if g.NoCacheDir != nil && *g.NoCacheDir {
		flags = append(flags, &Flag{ID: "cachedir", Flag: "--no-cache-dir", Args: nil})
	}
	if g.RmCacheDir != nil && *g.RmCacheDir {
		flags = append(flags, &Flag{ID: "rm_cachedir", Flag: "--rm-cache-dir", Args: nil})
	}
	return flags
}

type FlagsThumbnail struct {
	// Write thumbnail image to disk
	WriteThumbnail *bool `json:"write_thumbnail,omitempty" id:"writethumbnail" jsonschema:"title=WriteThumbnail" jsonschema_extras:"uid=writethumbnail" jsonschema_description:"Write thumbnail image to disk"`
	// Do not write thumbnail image to disk (default)
	NoWriteThumbnail *bool `json:"no_write_thumbnail,omitempty" id:"writethumbnail" jsonschema:"title=NoWriteThumbnail" jsonschema_extras:"uid=writethumbnail" jsonschema_description:"Do not write thumbnail image to disk (default)"`
	// Write all thumbnail image formats to disk
	WriteAllThumbnails *bool `json:"write_all_thumbnails,omitempty" id:"writethumbnail" jsonschema:"title=WriteAllThumbnails" jsonschema_extras:"uid=writethumbnail" jsonschema_description:"Write all thumbnail image formats to disk"`
	// List available thumbnails of each video. Simulate unless --no-simulate is used
	ListThumbnails *bool `json:"list_thumbnails,omitempty" id:"list_thumbnails" jsonschema:"title=ListThumbnails" jsonschema_extras:"uid=list_thumbnails" jsonschema_description:"List available thumbnails of each video. Simulate unless --no-simulate is used"`
}

// Validate ensures all flags have appropriate values. If there are validation-specific
// errors, they will be returned as a [ErrMultipleJSONParsingFlags] error.
func (g *FlagsThumbnail) Validate() error {
	if g == nil {
		return nil
	}

	var validationErrs []*ErrJSONParsingFlag

	duplicates := g.ToFlags().Duplicates()
	for _, duplicate := range duplicates {
		validationErrs = append(validationErrs, &ErrJSONParsingFlag{
			JSONPath: "thumbnail." + duplicate.ID,
			Flag:     duplicate.Flag,
			ID:       duplicate.ID,
			Err:      fmt.Errorf("duplicate flag (with conflicting ID %q) found: %v", duplicate.ID, duplicate.Flag),
		})
	}

	if len(validationErrs) > 0 {
		return &ErrMultipleJSONParsingFlags{Errors: validationErrs}
	}
	return nil
}

// ToFlags returns the generated flags based off the provided configuration. [FlagsThumbnail.Validate]
// should be called first.
func (g *FlagsThumbnail) ToFlags() (flags Flags) {
	if g == nil {
		return flags
	}
	if g.WriteThumbnail != nil && *g.WriteThumbnail {
		flags = append(flags, &Flag{ID: "writethumbnail", Flag: "--write-thumbnail", Args: nil})
	}
	if g.NoWriteThumbnail != nil && *g.NoWriteThumbnail {
		flags = append(flags, &Flag{ID: "writethumbnail", Flag: "--no-write-thumbnail", Args: nil})
	}
	if g.WriteAllThumbnails != nil && *g.WriteAllThumbnails {
		flags = append(flags, &Flag{ID: "writethumbnail", Flag: "--write-all-thumbnails", Args: nil})
	}
	if g.ListThumbnails != nil && *g.ListThumbnails {
		flags = append(flags, &Flag{ID: "list_thumbnails", Flag: "--list-thumbnails", Args: nil})
	}
	return flags
}

type FlagsInternetShortcut struct {
	// Write an internet shortcut file, depending on the current platform (.url, .webloc or
	// .desktop). The URL may be cached by the OS
	WriteLink *bool `json:"write_link,omitempty" id:"writelink" jsonschema:"title=WriteLink" jsonschema_extras:"uid=writelink" jsonschema_description:"Write an internet shortcut file, depending on the current platform (.url, .webloc or .desktop). The URL may be cached by the OS"`
	// Write a .url Windows internet shortcut. The OS caches the URL based on the file path
	WriteURLLink *bool `json:"write_url_link,omitempty" id:"writeurllink" jsonschema:"title=WriteURLLink" jsonschema_extras:"uid=writeurllink" jsonschema_description:"Write a .url Windows internet shortcut. The OS caches the URL based on the file path"`
	// Write a .webloc macOS internet shortcut
	WriteWeblocLink *bool `json:"write_webloc_link,omitempty" id:"writewebloclink" jsonschema:"title=WriteWeblocLink" jsonschema_extras:"uid=writewebloclink" jsonschema_description:"Write a .webloc macOS internet shortcut"`
	// Write a .desktop Linux internet shortcut
	WriteDesktopLink *bool `json:"write_desktop_link,omitempty" id:"writedesktoplink" jsonschema:"title=WriteDesktopLink" jsonschema_extras:"uid=writedesktoplink" jsonschema_description:"Write a .desktop Linux internet shortcut"`
}

// Validate ensures all flags have appropriate values. If there are validation-specific
// errors, they will be returned as a [ErrMultipleJSONParsingFlags] error.
func (g *FlagsInternetShortcut) Validate() error {
	if g == nil {
		return nil
	}

	var validationErrs []*ErrJSONParsingFlag

	duplicates := g.ToFlags().Duplicates()
	for _, duplicate := range duplicates {
		validationErrs = append(validationErrs, &ErrJSONParsingFlag{
			JSONPath: "internet_shortcut." + duplicate.ID,
			Flag:     duplicate.Flag,
			ID:       duplicate.ID,
			Err:      fmt.Errorf("duplicate flag (with conflicting ID %q) found: %v", duplicate.ID, duplicate.Flag),
		})
	}

	if len(validationErrs) > 0 {
		return &ErrMultipleJSONParsingFlags{Errors: validationErrs}
	}
	return nil
}

// ToFlags returns the generated flags based off the provided configuration. [FlagsInternetShortcut.Validate]
// should be called first.
func (g *FlagsInternetShortcut) ToFlags() (flags Flags) {
	if g == nil {
		return flags
	}
	if g.WriteLink != nil && *g.WriteLink {
		flags = append(flags, &Flag{ID: "writelink", Flag: "--write-link", Args: nil})
	}
	if g.WriteURLLink != nil && *g.WriteURLLink {
		flags = append(flags, &Flag{ID: "writeurllink", Flag: "--write-url-link", Args: nil})
	}
	if g.WriteWeblocLink != nil && *g.WriteWeblocLink {
		flags = append(flags, &Flag{ID: "writewebloclink", Flag: "--write-webloc-link", Args: nil})
	}
	if g.WriteDesktopLink != nil && *g.WriteDesktopLink {
		flags = append(flags, &Flag{ID: "writedesktoplink", Flag: "--write-desktop-link", Args: nil})
	}
	return flags
}

type FlagsVerbositySimulation struct {
	// Activate quiet mode. If used with --verbose, print the log to stderr
	Quiet *bool `json:"quiet,omitempty" id:"quiet" jsonschema:"title=Quiet" jsonschema_extras:"uid=quiet" jsonschema_description:"Activate quiet mode. If used with --verbose, print the log to stderr"`
	// Deactivate quiet mode. (Default)
	NoQuiet *bool `json:"no_quiet,omitempty" id:"quiet" jsonschema:"title=NoQuiet" jsonschema_extras:"uid=quiet" jsonschema_description:"Deactivate quiet mode. (Default)"`
	// Ignore warnings
	NoWarnings *bool `json:"no_warnings,omitempty" id:"no_warnings" jsonschema:"title=NoWarnings" jsonschema_extras:"uid=no_warnings" jsonschema_description:"Ignore warnings"`
	// Do not download the video and do not write anything to disk
	Simulate *bool `json:"simulate,omitempty" id:"simulate" jsonschema:"title=Simulate" jsonschema_extras:"uid=simulate" jsonschema_description:"Do not download the video and do not write anything to disk"`
	// Download the video even if printing/listing options are used
	NoSimulate *bool `json:"no_simulate,omitempty" id:"simulate" jsonschema:"title=NoSimulate" jsonschema_extras:"uid=simulate" jsonschema_description:"Download the video even if printing/listing options are used"`
	// Ignore "No video formats" error. Useful for extracting metadata even if the videos are not
	// actually available for download (experimental)
	IgnoreNoFormatsError *bool `json:"ignore_no_formats_error,omitempty" id:"ignore_no_formats_error" jsonschema:"title=IgnoreNoFormatsError" jsonschema_extras:"uid=ignore_no_formats_error" jsonschema_description:"Ignore \"No video formats\" error. Useful for extracting metadata even if the videos are not actually available for download (experimental)"`
	// Throw error when no downloadable video formats are found (default)
	NoIgnoreNoFormatsError *bool `json:"no_ignore_no_formats_error,omitempty" id:"ignore_no_formats_error" jsonschema:"title=NoIgnoreNoFormatsError" jsonschema_extras:"uid=ignore_no_formats_error" jsonschema_description:"Throw error when no downloadable video formats are found (default)"`
	// Do not download the video but write all related files
	SkipDownload *bool `json:"skip_download,omitempty" id:"skip_download" jsonschema:"title=SkipDownload" jsonschema_extras:"uid=skip_download" jsonschema_description:"Do not download the video but write all related files"`
	// Field name or output template to print to screen, optionally prefixed with when to print
	// it, separated by a ":". Supported values of "WHEN" are the same as that of
	// --use-postprocessor (default: video). Implies --quiet. Implies --simulate unless
	// --no-simulate or later stages of WHEN are used. This option can be used multiple times
	Print []string `json:"print,omitempty" id:"forceprint" jsonschema:"title=Print" jsonschema_extras:"uid=forceprint" jsonschema_description:"Field name or output template to print to screen, optionally prefixed with when to print it, separated by a \":\". Supported values of \"WHEN\" are the same as that of --use-postprocessor (default: video). Implies --quiet. Implies --simulate unless --no-simulate or later stages of WHEN are used. This option can be used multiple times"`
	// Append given template to the file. The values of WHEN and TEMPLATE are the same as that of
	// --print. FILE uses the same syntax as the output template. This option can be used
	// multiple times
	PrintToFile    []*FlagPrintToFile `json:"print_to_file,omitempty" id:"print_to_file" jsonschema:"title=PrintToFile" jsonschema_extras:"uid=print_to_file" jsonschema_description:"Append given template to the file. The values of WHEN and TEMPLATE are the same as that of --print. FILE uses the same syntax as the output template. This option can be used multiple times"`
	GetURL         *bool              `json:"get_url,omitempty" id:"geturl" jsonschema:"title=GetURL" jsonschema_extras:"uid=geturl" jsonschema_description:""`
	GetTitle       *bool              `json:"get_title,omitempty" id:"gettitle" jsonschema:"title=GetTitle" jsonschema_extras:"uid=gettitle" jsonschema_description:""`
	GetID          *bool              `json:"get_id,omitempty" id:"getid" jsonschema:"title=GetID" jsonschema_extras:"uid=getid" jsonschema_description:""`
	GetThumbnail   *bool              `json:"get_thumbnail,omitempty" id:"getthumbnail" jsonschema:"title=GetThumbnail" jsonschema_extras:"uid=getthumbnail" jsonschema_description:""`
	GetDescription *bool              `json:"get_description,omitempty" id:"getdescription" jsonschema:"title=GetDescription" jsonschema_extras:"uid=getdescription" jsonschema_description:""`
	GetDuration    *bool              `json:"get_duration,omitempty" id:"getduration" jsonschema:"title=GetDuration" jsonschema_extras:"uid=getduration" jsonschema_description:""`
	GetFilename    *bool              `json:"get_filename,omitempty" id:"getfilename" jsonschema:"title=GetFilename" jsonschema_extras:"uid=getfilename" jsonschema_description:""`
	GetFormat      *bool              `json:"get_format,omitempty" id:"getformat" jsonschema:"title=GetFormat" jsonschema_extras:"uid=getformat" jsonschema_description:""`
	// Quiet, but print JSON information for each video. Simulate unless --no-simulate is used.
	// See "OUTPUT TEMPLATE" for a description of available keys
	DumpJSON *bool `json:"dump_json,omitempty" id:"dumpjson" jsonschema:"title=DumpJSON" jsonschema_extras:"uid=dumpjson" jsonschema_description:"Quiet, but print JSON information for each video. Simulate unless --no-simulate is used. See \"OUTPUT TEMPLATE\" for a description of available keys"`
	// Quiet, but print JSON information for each URL or infojson passed. Simulate unless
	// --no-simulate is used. If the URL refers to a playlist, the whole playlist information is
	// dumped in a single line
	DumpSingleJSON *bool `json:"dump_single_json,omitempty" id:"dump_single_json" jsonschema:"title=DumpSingleJSON" jsonschema_extras:"uid=dump_single_json" jsonschema_description:"Quiet, but print JSON information for each URL or infojson passed. Simulate unless --no-simulate is used. If the URL refers to a playlist, the whole playlist information is dumped in a single line"`
	PrintJSON      *bool `json:"print_json,omitempty" id:"print_json" jsonschema:"title=PrintJSON" jsonschema_extras:"uid=print_json" jsonschema_description:""`
	// Force download archive entries to be written as far as no errors occur, even if -s or
	// another simulation option is used
	ForceWriteArchive *bool `json:"force_write_archive,omitempty" id:"force_write_download_archive" jsonschema:"title=ForceWriteArchive" jsonschema_extras:"uid=force_write_download_archive" jsonschema_description:"Force download archive entries to be written as far as no errors occur, even if -s or another simulation option is used"`
	// Output progress bar as new lines
	Newline *bool `json:"newline,omitempty" id:"progress_with_newline" jsonschema:"title=Newline" jsonschema_extras:"uid=progress_with_newline" jsonschema_description:"Output progress bar as new lines"`
	// Do not print progress bar
	NoProgress *bool `json:"no_progress,omitempty" id:"noprogress" jsonschema:"title=NoProgress" jsonschema_extras:"uid=noprogress" jsonschema_description:"Do not print progress bar"`
	// Show progress bar, even if in quiet mode
	Progress *bool `json:"progress,omitempty" id:"noprogress" jsonschema:"title=Progress" jsonschema_extras:"uid=noprogress" jsonschema_description:"Show progress bar, even if in quiet mode"`
	// Display progress in console titlebar
	ConsoleTitle *bool `json:"console_title,omitempty" id:"consoletitle" jsonschema:"title=ConsoleTitle" jsonschema_extras:"uid=consoletitle" jsonschema_description:"Display progress in console titlebar"`
	// Template for progress outputs, optionally prefixed with one of "download:" (default),
	// "download-title:" (the console title), "postprocess:",  or "postprocess-title:". The
	// video's fields are accessible under the "info" key and the progress attributes are
	// accessible under "progress" key. E.g. --console-title --progress-template
	// "download-title:%(info.id)s-%(progress.eta)s"
	ProgressTemplate *string `json:"progress_template,omitempty" id:"progress_template" jsonschema:"title=ProgressTemplate" jsonschema_extras:"uid=progress_template" jsonschema_description:"Template for progress outputs, optionally prefixed with one of \"download:\" (default), \"download-title:\" (the console title), \"postprocess:\",  or \"postprocess-title:\". The video's fields are accessible under the \"info\" key and the progress attributes are accessible under \"progress\" key. E.g. --console-title --progress-template \"download-title:%(info.id)s-%(progress.eta)s\""`
	// Time between progress output (default: 0)
	ProgressDelta *float64 `json:"progress_delta,omitempty" id:"progress_delta" jsonschema:"title=ProgressDelta" jsonschema_extras:"uid=progress_delta" jsonschema_description:"Time between progress output (default: 0)"`
	// Print various debugging information
	Verbose *bool `json:"verbose,omitempty" id:"verbose" jsonschema:"title=Verbose" jsonschema_extras:"uid=verbose" jsonschema_description:"Print various debugging information"`
	// Print downloaded pages encoded using base64 to debug problems (very verbose)
	DumpPages *bool `json:"dump_pages,omitempty" id:"dump_intermediate_pages" jsonschema:"title=DumpPages" jsonschema_extras:"uid=dump_intermediate_pages" jsonschema_description:"Print downloaded pages encoded using base64 to debug problems (very verbose)"`
	// Write downloaded intermediary pages to files in the current directory to debug problems
	WritePages *bool `json:"write_pages,omitempty" id:"write_pages" jsonschema:"title=WritePages" jsonschema_extras:"uid=write_pages" jsonschema_description:"Write downloaded intermediary pages to files in the current directory to debug problems"`
	// Display sent and read HTTP traffic
	PrintTraffic *bool `json:"print_traffic,omitempty" id:"debug_printtraffic" jsonschema:"title=PrintTraffic" jsonschema_extras:"uid=debug_printtraffic" jsonschema_description:"Display sent and read HTTP traffic"`
}

type FlagPrintToFile struct {
	Template string `json:"template,omitempty" jsonschema:"title=PrintToFile" jsonschema_extras:"uid=print_to_file" jsonschema_description:"Append given template to the file. The values of WHEN and TEMPLATE are the same as that of --print. FILE uses the same syntax as the output template. This option can be used multiple times"`
	File     string `json:"file,omitempty" jsonschema:"title=PrintToFile" jsonschema_extras:"uid=print_to_file" jsonschema_description:"Append given template to the file. The values of WHEN and TEMPLATE are the same as that of --print. FILE uses the same syntax as the output template. This option can be used multiple times"`
}

// Validate ensures all flags have appropriate values. If there are validation-specific
// errors, they will be returned as a [ErrMultipleJSONParsingFlags] error.
func (g *FlagsVerbositySimulation) Validate() error {
	if g == nil {
		return nil
	}

	var validationErrs []*ErrJSONParsingFlag

	duplicates := g.ToFlags().Duplicates()
	for _, duplicate := range duplicates {
		validationErrs = append(validationErrs, &ErrJSONParsingFlag{
			JSONPath: "verbosity_simulation." + duplicate.ID,
			Flag:     duplicate.Flag,
			ID:       duplicate.ID,
			Err:      fmt.Errorf("duplicate flag (with conflicting ID %q) found: %v", duplicate.ID, duplicate.Flag),
		})
	}

	if len(validationErrs) > 0 {
		return &ErrMultipleJSONParsingFlags{Errors: validationErrs}
	}
	return nil
}

// ToFlags returns the generated flags based off the provided configuration. [FlagsVerbositySimulation.Validate]
// should be called first.
func (g *FlagsVerbositySimulation) ToFlags() (flags Flags) {
	if g == nil {
		return flags
	}
	if g.Quiet != nil && *g.Quiet {
		flags = append(flags, &Flag{ID: "quiet", Flag: "--quiet", Args: nil})
	}
	if g.NoQuiet != nil && *g.NoQuiet {
		flags = append(flags, &Flag{ID: "quiet", Flag: "--no-quiet", Args: nil})
	}
	if g.NoWarnings != nil && *g.NoWarnings {
		flags = append(flags, &Flag{ID: "no_warnings", Flag: "--no-warnings", Args: nil})
	}
	if g.Simulate != nil && *g.Simulate {
		flags = append(flags, &Flag{ID: "simulate", Flag: "--simulate", Args: nil})
	}
	if g.NoSimulate != nil && *g.NoSimulate {
		flags = append(flags, &Flag{ID: "simulate", Flag: "--no-simulate", Args: nil})
	}
	if g.IgnoreNoFormatsError != nil && *g.IgnoreNoFormatsError {
		flags = append(flags, &Flag{ID: "ignore_no_formats_error", Flag: "--ignore-no-formats-error", Args: nil})
	}
	if g.NoIgnoreNoFormatsError != nil && *g.NoIgnoreNoFormatsError {
		flags = append(flags, &Flag{ID: "ignore_no_formats_error", Flag: "--no-ignore-no-formats-error", Args: nil})
	}
	if g.SkipDownload != nil && *g.SkipDownload {
		flags = append(flags, &Flag{ID: "skip_download", Flag: "--skip-download", Args: nil})
	}
	for _, v := range g.Print {
		flags = append(flags, &Flag{ID: "forceprint", Flag: "--print", AllowsMultiple: true, Args: []any{v}})
	}
	for _, v := range g.PrintToFile {
		flags = append(flags, &Flag{ID: "print_to_file", Flag: "--print-to-file", AllowsMultiple: true, Args: []any{v.Template, v.File}})
	}
	if g.GetURL != nil && *g.GetURL {
		flags = append(flags, &Flag{ID: "geturl", Flag: "--get-url", Args: nil})
	}
	if g.GetTitle != nil && *g.GetTitle {
		flags = append(flags, &Flag{ID: "gettitle", Flag: "--get-title", Args: nil})
	}
	if g.GetID != nil && *g.GetID {
		flags = append(flags, &Flag{ID: "getid", Flag: "--get-id", Args: nil})
	}
	if g.GetThumbnail != nil && *g.GetThumbnail {
		flags = append(flags, &Flag{ID: "getthumbnail", Flag: "--get-thumbnail", Args: nil})
	}
	if g.GetDescription != nil && *g.GetDescription {
		flags = append(flags, &Flag{ID: "getdescription", Flag: "--get-description", Args: nil})
	}
	if g.GetDuration != nil && *g.GetDuration {
		flags = append(flags, &Flag{ID: "getduration", Flag: "--get-duration", Args: nil})
	}
	if g.GetFilename != nil && *g.GetFilename {
		flags = append(flags, &Flag{ID: "getfilename", Flag: "--get-filename", Args: nil})
	}
	if g.GetFormat != nil && *g.GetFormat {
		flags = append(flags, &Flag{ID: "getformat", Flag: "--get-format", Args: nil})
	}
	if g.DumpJSON != nil && *g.DumpJSON {
		flags = append(flags, &Flag{ID: "dumpjson", Flag: "--dump-json", Args: nil})
	}
	if g.DumpSingleJSON != nil && *g.DumpSingleJSON {
		flags = append(flags, &Flag{ID: "dump_single_json", Flag: "--dump-single-json", Args: nil})
	}
	if g.PrintJSON != nil && *g.PrintJSON {
		flags = append(flags, &Flag{ID: "print_json", Flag: "--print-json", Args: nil})
	}
	if g.ForceWriteArchive != nil && *g.ForceWriteArchive {
		flags = append(flags, &Flag{ID: "force_write_download_archive", Flag: "--force-write-archive", Args: nil})
	}
	if g.Newline != nil && *g.Newline {
		flags = append(flags, &Flag{ID: "progress_with_newline", Flag: "--newline", Args: nil})
	}
	if g.NoProgress != nil && *g.NoProgress {
		flags = append(flags, &Flag{ID: "noprogress", Flag: "--no-progress", Args: nil})
	}
	if g.Progress != nil && *g.Progress {
		flags = append(flags, &Flag{ID: "noprogress", Flag: "--progress", Args: nil})
	}
	if g.ConsoleTitle != nil && *g.ConsoleTitle {
		flags = append(flags, &Flag{ID: "consoletitle", Flag: "--console-title", Args: nil})
	}
	if g.ProgressTemplate != nil {
		flags = append(flags, &Flag{ID: "progress_template", Flag: "--progress-template", Args: []any{*g.ProgressTemplate}})
	}
	if g.ProgressDelta != nil {
		flags = append(flags, &Flag{ID: "progress_delta", Flag: "--progress-delta", Args: []any{*g.ProgressDelta}})
	}
	if g.Verbose != nil && *g.Verbose {
		flags = append(flags, &Flag{ID: "verbose", Flag: "--verbose", Args: nil})
	}
	if g.DumpPages != nil && *g.DumpPages {
		flags = append(flags, &Flag{ID: "dump_intermediate_pages", Flag: "--dump-pages", Args: nil})
	}
	if g.WritePages != nil && *g.WritePages {
		flags = append(flags, &Flag{ID: "write_pages", Flag: "--write-pages", Args: nil})
	}
	if g.PrintTraffic != nil && *g.PrintTraffic {
		flags = append(flags, &Flag{ID: "debug_printtraffic", Flag: "--print-traffic", Args: nil})
	}
	return flags
}

type FlagsWorkarounds struct {
	// Force the specified encoding (experimental)
	Encoding *string `json:"encoding,omitempty" id:"encoding" jsonschema:"title=Encoding" jsonschema_extras:"uid=encoding" jsonschema_description:"Force the specified encoding (experimental)"`
	// Explicitly allow HTTPS connection to servers that do not support RFC 5746 secure
	// renegotiation
	LegacyServerConnect *bool `json:"legacy_server_connect,omitempty" id:"legacy_server_connect" jsonschema:"title=LegacyServerConnect" jsonschema_extras:"uid=legacy_server_connect" jsonschema_description:"Explicitly allow HTTPS connection to servers that do not support RFC 5746 secure renegotiation"`
	// Suppress HTTPS certificate validation
	NoCheckCertificates *bool `json:"no_check_certificates,omitempty" id:"no_check_certificate" jsonschema:"title=NoCheckCertificates" jsonschema_extras:"uid=no_check_certificate" jsonschema_description:"Suppress HTTPS certificate validation"`
	// Use an unencrypted connection to retrieve information about the video (Currently supported
	// only for YouTube)
	PreferInsecure *bool   `json:"prefer_insecure,omitempty" id:"prefer_insecure" jsonschema:"title=PreferInsecure" jsonschema_extras:"uid=prefer_insecure" jsonschema_description:"Use an unencrypted connection to retrieve information about the video (Currently supported only for YouTube)"`
	UserAgent      *string `json:"user_agent,omitempty" id:"user_agent" jsonschema:"title=UserAgent" jsonschema_extras:"uid=user_agent" jsonschema_description:""`
	Referer        *string `json:"referer,omitempty" id:"referer" jsonschema:"title=Referer" jsonschema_extras:"uid=referer" jsonschema_description:""`
	// Specify a custom HTTP header and its value, separated by a colon ":". You can use this
	// option multiple times
	AddHeaders []string `json:"add_headers,omitempty" id:"headers" jsonschema:"title=AddHeaders" jsonschema_extras:"uid=headers" jsonschema_description:"Specify a custom HTTP header and its value, separated by a colon \":\". You can use this option multiple times"`
	// Work around terminals that lack bidirectional text support. Requires bidiv or fribidi
	// executable in PATH
	BidiWorkaround *bool `json:"bidi_workaround,omitempty" id:"bidi_workaround" jsonschema:"title=BidiWorkaround" jsonschema_extras:"uid=bidi_workaround" jsonschema_description:"Work around terminals that lack bidirectional text support. Requires bidiv or fribidi executable in PATH"`
	// Number of seconds to sleep between requests during data extraction
	SleepRequests *float64 `json:"sleep_requests,omitempty" id:"sleep_interval_requests" jsonschema:"title=SleepRequests" jsonschema_extras:"uid=sleep_interval_requests" jsonschema_description:"Number of seconds to sleep between requests during data extraction"`
	// Number of seconds to sleep before each download. This is the minimum time to sleep when
	// used along with --max-sleep-interval
	SleepInterval *float64 `json:"sleep_interval,omitempty" id:"sleep_interval" jsonschema:"title=SleepInterval" jsonschema_extras:"uid=sleep_interval" jsonschema_description:"Number of seconds to sleep before each download. This is the minimum time to sleep when used along with --max-sleep-interval"`
	// Maximum number of seconds to sleep. Can only be used along with --min-sleep-interval
	MaxSleepInterval *float64 `json:"max_sleep_interval,omitempty" id:"max_sleep_interval" jsonschema:"title=MaxSleepInterval" jsonschema_extras:"uid=max_sleep_interval" jsonschema_description:"Maximum number of seconds to sleep. Can only be used along with --min-sleep-interval"`
	// Number of seconds to sleep before each subtitle download
	SleepSubtitles *int `json:"sleep_subtitles,omitempty" id:"sleep_interval_subtitles" jsonschema:"title=SleepSubtitles" jsonschema_extras:"uid=sleep_interval_subtitles" jsonschema_description:"Number of seconds to sleep before each subtitle download"`
}

// Validate ensures all flags have appropriate values. If there are validation-specific
// errors, they will be returned as a [ErrMultipleJSONParsingFlags] error.
func (g *FlagsWorkarounds) Validate() error {
	if g == nil {
		return nil
	}

	var validationErrs []*ErrJSONParsingFlag

	duplicates := g.ToFlags().Duplicates()
	for _, duplicate := range duplicates {
		validationErrs = append(validationErrs, &ErrJSONParsingFlag{
			JSONPath: "workarounds." + duplicate.ID,
			Flag:     duplicate.Flag,
			ID:       duplicate.ID,
			Err:      fmt.Errorf("duplicate flag (with conflicting ID %q) found: %v", duplicate.ID, duplicate.Flag),
		})
	}

	if len(validationErrs) > 0 {
		return &ErrMultipleJSONParsingFlags{Errors: validationErrs}
	}
	return nil
}

// ToFlags returns the generated flags based off the provided configuration. [FlagsWorkarounds.Validate]
// should be called first.
func (g *FlagsWorkarounds) ToFlags() (flags Flags) {
	if g == nil {
		return flags
	}
	if g.Encoding != nil {
		flags = append(flags, &Flag{ID: "encoding", Flag: "--encoding", Args: []any{*g.Encoding}})
	}
	if g.LegacyServerConnect != nil && *g.LegacyServerConnect {
		flags = append(flags, &Flag{ID: "legacy_server_connect", Flag: "--legacy-server-connect", Args: nil})
	}
	if g.NoCheckCertificates != nil && *g.NoCheckCertificates {
		flags = append(flags, &Flag{ID: "no_check_certificate", Flag: "--no-check-certificates", Args: nil})
	}
	if g.PreferInsecure != nil && *g.PreferInsecure {
		flags = append(flags, &Flag{ID: "prefer_insecure", Flag: "--prefer-insecure", Args: nil})
	}
	if g.UserAgent != nil {
		flags = append(flags, &Flag{ID: "user_agent", Flag: "--user-agent", Args: []any{*g.UserAgent}})
	}
	if g.Referer != nil {
		flags = append(flags, &Flag{ID: "referer", Flag: "--referer", Args: []any{*g.Referer}})
	}
	for _, v := range g.AddHeaders {
		flags = append(flags, &Flag{ID: "headers", Flag: "--add-headers", AllowsMultiple: true, Args: []any{v}})
	}
	if g.BidiWorkaround != nil && *g.BidiWorkaround {
		flags = append(flags, &Flag{ID: "bidi_workaround", Flag: "--bidi-workaround", Args: nil})
	}
	if g.SleepRequests != nil {
		flags = append(flags, &Flag{ID: "sleep_interval_requests", Flag: "--sleep-requests", Args: []any{*g.SleepRequests}})
	}
	if g.SleepInterval != nil {
		flags = append(flags, &Flag{ID: "sleep_interval", Flag: "--sleep-interval", Args: []any{*g.SleepInterval}})
	}
	if g.MaxSleepInterval != nil {
		flags = append(flags, &Flag{ID: "max_sleep_interval", Flag: "--max-sleep-interval", Args: []any{*g.MaxSleepInterval}})
	}
	if g.SleepSubtitles != nil {
		flags = append(flags, &Flag{ID: "sleep_interval_subtitles", Flag: "--sleep-subtitles", Args: []any{*g.SleepSubtitles}})
	}
	return flags
}

type FlagsVideoFormat struct {
	// Video format code, see "FORMAT SELECTION" for more details
	Format *string `json:"format,omitempty" id:"format" jsonschema:"title=Format" jsonschema_extras:"uid=format" jsonschema_description:"Video format code, see \"FORMAT SELECTION\" for more details"`
	// Sort the formats by the fields given, see "Sorting Formats" for more details
	FormatSort *string `json:"format_sort,omitempty" id:"format_sort" jsonschema:"title=FormatSort" jsonschema_extras:"uid=format_sort" jsonschema_description:"Sort the formats by the fields given, see \"Sorting Formats\" for more details"`
	// Force user specified sort order to have precedence over all fields, see "Sorting Formats"
	// for more details
	FormatSortForce *bool `json:"format_sort_force,omitempty" id:"format_sort_force" jsonschema:"title=FormatSortForce" jsonschema_extras:"uid=format_sort_force" jsonschema_description:"Force user specified sort order to have precedence over all fields, see \"Sorting Formats\" for more details"`
	// Some fields have precedence over the user specified sort order (default)
	NoFormatSortForce *bool `json:"no_format_sort_force,omitempty" id:"format_sort_force" jsonschema:"title=NoFormatSortForce" jsonschema_extras:"uid=format_sort_force" jsonschema_description:"Some fields have precedence over the user specified sort order (default)"`
	// Allow multiple video streams to be merged into a single file
	VideoMultistreams *bool `json:"video_multistreams,omitempty" id:"allow_multiple_video_streams" jsonschema:"title=VideoMultistreams" jsonschema_extras:"uid=allow_multiple_video_streams" jsonschema_description:"Allow multiple video streams to be merged into a single file"`
	// Only one video stream is downloaded for each output file (default)
	NoVideoMultistreams *bool `json:"no_video_multistreams,omitempty" id:"allow_multiple_video_streams" jsonschema:"title=NoVideoMultistreams" jsonschema_extras:"uid=allow_multiple_video_streams" jsonschema_description:"Only one video stream is downloaded for each output file (default)"`
	// Allow multiple audio streams to be merged into a single file
	AudioMultistreams *bool `json:"audio_multistreams,omitempty" id:"allow_multiple_audio_streams" jsonschema:"title=AudioMultistreams" jsonschema_extras:"uid=allow_multiple_audio_streams" jsonschema_description:"Allow multiple audio streams to be merged into a single file"`
	// Only one audio stream is downloaded for each output file (default)
	NoAudioMultistreams *bool `json:"no_audio_multistreams,omitempty" id:"allow_multiple_audio_streams" jsonschema:"title=NoAudioMultistreams" jsonschema_extras:"uid=allow_multiple_audio_streams" jsonschema_description:"Only one audio stream is downloaded for each output file (default)"`
	AllFormats          *bool `json:"all_formats,omitempty" id:"format" jsonschema:"title=AllFormats" jsonschema_extras:"uid=format" jsonschema_description:""`
	// Prefer video formats with free containers over non-free ones of the same quality. Use with
	// "-S ext" to strictly prefer free containers irrespective of quality
	PreferFreeFormats *bool `json:"prefer_free_formats,omitempty" id:"prefer_free_formats" jsonschema:"title=PreferFreeFormats" jsonschema_extras:"uid=prefer_free_formats" jsonschema_description:"Prefer video formats with free containers over non-free ones of the same quality. Use with \"-S ext\" to strictly prefer free containers irrespective of quality"`
	// Don't give any special preference to free containers (default)
	NoPreferFreeFormats *bool `json:"no_prefer_free_formats,omitempty" id:"prefer_free_formats" jsonschema:"title=NoPreferFreeFormats" jsonschema_extras:"uid=prefer_free_formats" jsonschema_description:"Don't give any special preference to free containers (default)"`
	// Make sure formats are selected only from those that are actually downloadable
	CheckFormats *bool `json:"check_formats,omitempty" id:"check_formats" jsonschema:"title=CheckFormats" jsonschema_extras:"uid=check_formats" jsonschema_description:"Make sure formats are selected only from those that are actually downloadable"`
	// Check all formats for whether they are actually downloadable
	CheckAllFormats *bool `json:"check_all_formats,omitempty" id:"check_formats" jsonschema:"title=CheckAllFormats" jsonschema_extras:"uid=check_formats" jsonschema_description:"Check all formats for whether they are actually downloadable"`
	// Do not check that the formats are actually downloadable
	NoCheckFormats *bool `json:"no_check_formats,omitempty" id:"check_formats" jsonschema:"title=NoCheckFormats" jsonschema_extras:"uid=check_formats" jsonschema_description:"Do not check that the formats are actually downloadable"`
	// List available formats of each video. Simulate unless --no-simulate is used
	ListFormats        *bool `json:"list_formats,omitempty" id:"listformats" jsonschema:"title=ListFormats" jsonschema_extras:"uid=listformats" jsonschema_description:"List available formats of each video. Simulate unless --no-simulate is used"`
	ListFormatsAsTable *bool `json:"list_formats_as_table,omitempty" id:"listformats_table" jsonschema:"title=ListFormatsAsTable" jsonschema_extras:"uid=listformats_table" jsonschema_description:""`
	ListFormatsOld     *bool `json:"list_formats_old,omitempty" id:"listformats_table" jsonschema:"title=ListFormatsOld" jsonschema_extras:"uid=listformats_table" jsonschema_description:""`
	// Containers that may be used when merging formats, separated by "/", e.g. "mp4/mkv".
	// Ignored if no merge is required. (currently supported: avi, flv, mkv, mov, mp4, webm)
	MergeOutputFormat *string `json:"merge_output_format,omitempty" id:"merge_output_format" jsonschema:"title=MergeOutputFormat" jsonschema_extras:"uid=merge_output_format" jsonschema_description:"Containers that may be used when merging formats, separated by \"/\", e.g. \"mp4/mkv\". Ignored if no merge is required. (currently supported: avi, flv, mkv, mov, mp4, webm)"`
}

// Validate ensures all flags have appropriate values. If there are validation-specific
// errors, they will be returned as a [ErrMultipleJSONParsingFlags] error.
func (g *FlagsVideoFormat) Validate() error {
	if g == nil {
		return nil
	}

	var validationErrs []*ErrJSONParsingFlag

	duplicates := g.ToFlags().Duplicates()
	for _, duplicate := range duplicates {
		validationErrs = append(validationErrs, &ErrJSONParsingFlag{
			JSONPath: "video_format." + duplicate.ID,
			Flag:     duplicate.Flag,
			ID:       duplicate.ID,
			Err:      fmt.Errorf("duplicate flag (with conflicting ID %q) found: %v", duplicate.ID, duplicate.Flag),
		})
	}

	if len(validationErrs) > 0 {
		return &ErrMultipleJSONParsingFlags{Errors: validationErrs}
	}
	return nil
}

// ToFlags returns the generated flags based off the provided configuration. [FlagsVideoFormat.Validate]
// should be called first.
func (g *FlagsVideoFormat) ToFlags() (flags Flags) {
	if g == nil {
		return flags
	}
	if g.Format != nil {
		flags = append(flags, &Flag{ID: "format", Flag: "--format", Args: []any{*g.Format}})
	}
	if g.FormatSort != nil {
		flags = append(flags, &Flag{ID: "format_sort", Flag: "--format-sort", Args: []any{*g.FormatSort}})
	}
	if g.FormatSortForce != nil && *g.FormatSortForce {
		flags = append(flags, &Flag{ID: "format_sort_force", Flag: "--format-sort-force", Args: nil})
	}
	if g.NoFormatSortForce != nil && *g.NoFormatSortForce {
		flags = append(flags, &Flag{ID: "format_sort_force", Flag: "--no-format-sort-force", Args: nil})
	}
	if g.VideoMultistreams != nil && *g.VideoMultistreams {
		flags = append(flags, &Flag{ID: "allow_multiple_video_streams", Flag: "--video-multistreams", Args: nil})
	}
	if g.NoVideoMultistreams != nil && *g.NoVideoMultistreams {
		flags = append(flags, &Flag{ID: "allow_multiple_video_streams", Flag: "--no-video-multistreams", Args: nil})
	}
	if g.AudioMultistreams != nil && *g.AudioMultistreams {
		flags = append(flags, &Flag{ID: "allow_multiple_audio_streams", Flag: "--audio-multistreams", Args: nil})
	}
	if g.NoAudioMultistreams != nil && *g.NoAudioMultistreams {
		flags = append(flags, &Flag{ID: "allow_multiple_audio_streams", Flag: "--no-audio-multistreams", Args: nil})
	}
	if g.AllFormats != nil && *g.AllFormats {
		flags = append(flags, &Flag{ID: "format", Flag: "--all-formats", Args: nil})
	}
	if g.PreferFreeFormats != nil && *g.PreferFreeFormats {
		flags = append(flags, &Flag{ID: "prefer_free_formats", Flag: "--prefer-free-formats", Args: nil})
	}
	if g.NoPreferFreeFormats != nil && *g.NoPreferFreeFormats {
		flags = append(flags, &Flag{ID: "prefer_free_formats", Flag: "--no-prefer-free-formats", Args: nil})
	}
	if g.CheckFormats != nil && *g.CheckFormats {
		flags = append(flags, &Flag{ID: "check_formats", Flag: "--check-formats", Args: nil})
	}
	if g.CheckAllFormats != nil && *g.CheckAllFormats {
		flags = append(flags, &Flag{ID: "check_formats", Flag: "--check-all-formats", Args: nil})
	}
	if g.NoCheckFormats != nil && *g.NoCheckFormats {
		flags = append(flags, &Flag{ID: "check_formats", Flag: "--no-check-formats", Args: nil})
	}
	if g.ListFormats != nil && *g.ListFormats {
		flags = append(flags, &Flag{ID: "listformats", Flag: "--list-formats", Args: nil})
	}
	if g.ListFormatsAsTable != nil && *g.ListFormatsAsTable {
		flags = append(flags, &Flag{ID: "listformats_table", Flag: "--list-formats-as-table", Args: nil})
	}
	if g.ListFormatsOld != nil && *g.ListFormatsOld {
		flags = append(flags, &Flag{ID: "listformats_table", Flag: "--list-formats-old", Args: nil})
	}
	if g.MergeOutputFormat != nil {
		flags = append(flags, &Flag{ID: "merge_output_format", Flag: "--merge-output-format", Args: []any{*g.MergeOutputFormat}})
	}
	return flags
}

type FlagsSubtitle struct {
	// Write subtitle file
	WriteSubs *bool `json:"write_subs,omitempty" id:"writesubtitles" jsonschema:"title=WriteSubs" jsonschema_extras:"uid=writesubtitles" jsonschema_description:"Write subtitle file"`
	// Do not write subtitle file (default)
	NoWriteSubs *bool `json:"no_write_subs,omitempty" id:"writesubtitles" jsonschema:"title=NoWriteSubs" jsonschema_extras:"uid=writesubtitles" jsonschema_description:"Do not write subtitle file (default)"`
	// Write automatically generated subtitle file
	WriteAutoSubs *bool `json:"write_auto_subs,omitempty" id:"writeautomaticsub" jsonschema:"title=WriteAutoSubs" jsonschema_extras:"uid=writeautomaticsub" jsonschema_description:"Write automatically generated subtitle file"`
	// Do not write auto-generated subtitles (default)
	NoWriteAutoSubs *bool `json:"no_write_auto_subs,omitempty" id:"writeautomaticsub" jsonschema:"title=NoWriteAutoSubs" jsonschema_extras:"uid=writeautomaticsub" jsonschema_description:"Do not write auto-generated subtitles (default)"`
	AllSubs         *bool `json:"all_subs,omitempty" id:"allsubtitles" jsonschema:"title=AllSubs" jsonschema_extras:"uid=allsubtitles" jsonschema_description:""`
	// List available subtitles of each video. Simulate unless --no-simulate is used
	ListSubs *bool `json:"list_subs,omitempty" id:"listsubtitles" jsonschema:"title=ListSubs" jsonschema_extras:"uid=listsubtitles" jsonschema_description:"List available subtitles of each video. Simulate unless --no-simulate is used"`
	// Subtitle format; accepts formats preference separated by "/", e.g. "srt" or "ass/srt/best"
	SubFormat *string `json:"sub_format,omitempty" id:"subtitlesformat" jsonschema:"title=SubFormat" jsonschema_extras:"uid=subtitlesformat" jsonschema_description:"Subtitle format; accepts formats preference separated by \"/\", e.g. \"srt\" or \"ass/srt/best\""`
	// Languages of the subtitles to download (can be regex) or "all" separated by commas, e.g.
	// --sub-langs "en.*,ja" (where "en.*" is a regex pattern that matches "en" followed by 0 or
	// more of any character). You can prefix the language code with a "-" to exclude it from the
	// requested languages, e.g. --sub-langs all,-live_chat. Use --list-subs for a list of
	// available language tags
	SubLangs *string `json:"sub_langs,omitempty" id:"subtitleslangs" jsonschema:"title=SubLangs" jsonschema_extras:"uid=subtitleslangs" jsonschema_description:"Languages of the subtitles to download (can be regex) or \"all\" separated by commas, e.g. --sub-langs \"en.*,ja\" (where \"en.*\" is a regex pattern that matches \"en\" followed by 0 or more of any character). You can prefix the language code with a \"-\" to exclude it from the requested languages, e.g. --sub-langs all,-live_chat. Use --list-subs for a list of available language tags"`
}

// Validate ensures all flags have appropriate values. If there are validation-specific
// errors, they will be returned as a [ErrMultipleJSONParsingFlags] error.
func (g *FlagsSubtitle) Validate() error {
	if g == nil {
		return nil
	}

	var validationErrs []*ErrJSONParsingFlag

	duplicates := g.ToFlags().Duplicates()
	for _, duplicate := range duplicates {
		validationErrs = append(validationErrs, &ErrJSONParsingFlag{
			JSONPath: "subtitle." + duplicate.ID,
			Flag:     duplicate.Flag,
			ID:       duplicate.ID,
			Err:      fmt.Errorf("duplicate flag (with conflicting ID %q) found: %v", duplicate.ID, duplicate.Flag),
		})
	}

	if len(validationErrs) > 0 {
		return &ErrMultipleJSONParsingFlags{Errors: validationErrs}
	}
	return nil
}

// ToFlags returns the generated flags based off the provided configuration. [FlagsSubtitle.Validate]
// should be called first.
func (g *FlagsSubtitle) ToFlags() (flags Flags) {
	if g == nil {
		return flags
	}
	if g.WriteSubs != nil && *g.WriteSubs {
		flags = append(flags, &Flag{ID: "writesubtitles", Flag: "--write-subs", Args: nil})
	}
	if g.NoWriteSubs != nil && *g.NoWriteSubs {
		flags = append(flags, &Flag{ID: "writesubtitles", Flag: "--no-write-subs", Args: nil})
	}
	if g.WriteAutoSubs != nil && *g.WriteAutoSubs {
		flags = append(flags, &Flag{ID: "writeautomaticsub", Flag: "--write-auto-subs", Args: nil})
	}
	if g.NoWriteAutoSubs != nil && *g.NoWriteAutoSubs {
		flags = append(flags, &Flag{ID: "writeautomaticsub", Flag: "--no-write-auto-subs", Args: nil})
	}
	if g.AllSubs != nil && *g.AllSubs {
		flags = append(flags, &Flag{ID: "allsubtitles", Flag: "--all-subs", Args: nil})
	}
	if g.ListSubs != nil && *g.ListSubs {
		flags = append(flags, &Flag{ID: "listsubtitles", Flag: "--list-subs", Args: nil})
	}
	if g.SubFormat != nil {
		flags = append(flags, &Flag{ID: "subtitlesformat", Flag: "--sub-format", Args: []any{*g.SubFormat}})
	}
	if g.SubLangs != nil {
		flags = append(flags, &Flag{ID: "subtitleslangs", Flag: "--sub-langs", Args: []any{*g.SubLangs}})
	}
	return flags
}

type FlagsAuthentication struct {
	// Login with this account ID
	Username *string `json:"username,omitempty" id:"username" jsonschema:"title=Username" jsonschema_extras:"uid=username" jsonschema_description:"Login with this account ID"`
	// Account password. If this option is left out, yt-dlp will ask interactively
	Password *string `json:"password,omitempty" id:"password" jsonschema:"title=Password" jsonschema_extras:"uid=password" jsonschema_description:"Account password. If this option is left out, yt-dlp will ask interactively"`
	// Two-factor authentication code
	TwoFactor *string `json:"twofactor,omitempty" id:"twofactor" jsonschema:"title=TwoFactor" jsonschema_extras:"uid=twofactor" jsonschema_description:"Two-factor authentication code"`
	// Use .netrc authentication data
	Netrc *bool `json:"netrc,omitempty" id:"usenetrc" jsonschema:"title=Netrc" jsonschema_extras:"uid=usenetrc" jsonschema_description:"Use .netrc authentication data"`
	// Location of .netrc authentication data; either the path or its containing directory.
	// Defaults to ~/.netrc
	NetrcLocation *string `json:"netrc_location,omitempty" id:"netrc_location" jsonschema:"title=NetrcLocation" jsonschema_extras:"uid=netrc_location" jsonschema_description:"Location of .netrc authentication data; either the path or its containing directory. Defaults to ~/.netrc"`
	// Command to execute to get the credentials for an extractor.
	NetrcCmd *string `json:"netrc_cmd,omitempty" id:"netrc_cmd" jsonschema:"title=NetrcCmd" jsonschema_extras:"uid=netrc_cmd" jsonschema_description:"Command to execute to get the credentials for an extractor."`
	// Video-specific password
	VideoPassword *string `json:"video_password,omitempty" id:"videopassword" jsonschema:"title=VideoPassword" jsonschema_extras:"uid=videopassword" jsonschema_description:"Video-specific password"`
	// Adobe Pass multiple-system operator (TV provider) identifier, use --ap-list-mso for a list
	// of available MSOs
	ApMSO *string `json:"ap_mso,omitempty" id:"ap_mso" jsonschema:"title=ApMSO" jsonschema_extras:"uid=ap_mso" jsonschema_description:"Adobe Pass multiple-system operator (TV provider) identifier, use --ap-list-mso for a list of available MSOs"`
	// Multiple-system operator account login
	ApUsername *string `json:"ap_username,omitempty" id:"ap_username" jsonschema:"title=ApUsername" jsonschema_extras:"uid=ap_username" jsonschema_description:"Multiple-system operator account login"`
	// Multiple-system operator account password. If this option is left out, yt-dlp will ask
	// interactively
	ApPassword *string `json:"ap_password,omitempty" id:"ap_password" jsonschema:"title=ApPassword" jsonschema_extras:"uid=ap_password" jsonschema_description:"Multiple-system operator account password. If this option is left out, yt-dlp will ask interactively"`
	// List all supported multiple-system operators
	ApListMSO *bool `json:"ap_list_mso,omitempty" id:"ap_list_mso" jsonschema:"title=ApListMSO" jsonschema_extras:"uid=ap_list_mso" jsonschema_description:"List all supported multiple-system operators"`
	// Path to client certificate file in PEM format. May include the private key
	ClientCertificate *string `json:"client_certificate,omitempty" id:"client_certificate" jsonschema:"title=ClientCertificate" jsonschema_extras:"uid=client_certificate" jsonschema_description:"Path to client certificate file in PEM format. May include the private key"`
	// Path to private key file for client certificate
	ClientCertificateKey *string `json:"client_certificate_key,omitempty" id:"client_certificate_key" jsonschema:"title=ClientCertificateKey" jsonschema_extras:"uid=client_certificate_key" jsonschema_description:"Path to private key file for client certificate"`
	// Password for client certificate private key, if encrypted. If not provided, and the key is
	// encrypted, yt-dlp will ask interactively
	ClientCertificatePassword *string `json:"client_certificate_password,omitempty" id:"client_certificate_password" jsonschema:"title=ClientCertificatePassword" jsonschema_extras:"uid=client_certificate_password" jsonschema_description:"Password for client certificate private key, if encrypted. If not provided, and the key is encrypted, yt-dlp will ask interactively"`
}

// Validate ensures all flags have appropriate values. If there are validation-specific
// errors, they will be returned as a [ErrMultipleJSONParsingFlags] error.
func (g *FlagsAuthentication) Validate() error {
	if g == nil {
		return nil
	}

	var validationErrs []*ErrJSONParsingFlag

	duplicates := g.ToFlags().Duplicates()
	for _, duplicate := range duplicates {
		validationErrs = append(validationErrs, &ErrJSONParsingFlag{
			JSONPath: "authentication." + duplicate.ID,
			Flag:     duplicate.Flag,
			ID:       duplicate.ID,
			Err:      fmt.Errorf("duplicate flag (with conflicting ID %q) found: %v", duplicate.ID, duplicate.Flag),
		})
	}

	if len(validationErrs) > 0 {
		return &ErrMultipleJSONParsingFlags{Errors: validationErrs}
	}
	return nil
}

// ToFlags returns the generated flags based off the provided configuration. [FlagsAuthentication.Validate]
// should be called first.
func (g *FlagsAuthentication) ToFlags() (flags Flags) {
	if g == nil {
		return flags
	}
	if g.Username != nil {
		flags = append(flags, &Flag{ID: "username", Flag: "--username", Args: []any{*g.Username}})
	}
	if g.Password != nil {
		flags = append(flags, &Flag{ID: "password", Flag: "--password", Args: []any{*g.Password}})
	}
	if g.TwoFactor != nil {
		flags = append(flags, &Flag{ID: "twofactor", Flag: "--twofactor", Args: []any{*g.TwoFactor}})
	}
	if g.Netrc != nil && *g.Netrc {
		flags = append(flags, &Flag{ID: "usenetrc", Flag: "--netrc", Args: nil})
	}
	if g.NetrcLocation != nil {
		flags = append(flags, &Flag{ID: "netrc_location", Flag: "--netrc-location", Args: []any{*g.NetrcLocation}})
	}
	if g.NetrcCmd != nil {
		flags = append(flags, &Flag{ID: "netrc_cmd", Flag: "--netrc-cmd", Args: []any{*g.NetrcCmd}})
	}
	if g.VideoPassword != nil {
		flags = append(flags, &Flag{ID: "videopassword", Flag: "--video-password", Args: []any{*g.VideoPassword}})
	}
	if g.ApMSO != nil {
		flags = append(flags, &Flag{ID: "ap_mso", Flag: "--ap-mso", Args: []any{*g.ApMSO}})
	}
	if g.ApUsername != nil {
		flags = append(flags, &Flag{ID: "ap_username", Flag: "--ap-username", Args: []any{*g.ApUsername}})
	}
	if g.ApPassword != nil {
		flags = append(flags, &Flag{ID: "ap_password", Flag: "--ap-password", Args: []any{*g.ApPassword}})
	}
	if g.ApListMSO != nil && *g.ApListMSO {
		flags = append(flags, &Flag{ID: "ap_list_mso", Flag: "--ap-list-mso", Args: nil})
	}
	if g.ClientCertificate != nil {
		flags = append(flags, &Flag{ID: "client_certificate", Flag: "--client-certificate", Args: []any{*g.ClientCertificate}})
	}
	if g.ClientCertificateKey != nil {
		flags = append(flags, &Flag{ID: "client_certificate_key", Flag: "--client-certificate-key", Args: []any{*g.ClientCertificateKey}})
	}
	if g.ClientCertificatePassword != nil {
		flags = append(flags, &Flag{ID: "client_certificate_password", Flag: "--client-certificate-password", Args: []any{*g.ClientCertificatePassword}})
	}
	return flags
}

type FlagsPostProcessing struct {
	// Convert video files to audio-only files (requires ffmpeg and ffprobe)
	ExtractAudio *bool `json:"extract_audio,omitempty" id:"extractaudio" jsonschema:"title=ExtractAudio" jsonschema_extras:"uid=extractaudio" jsonschema_description:"Convert video files to audio-only files (requires ffmpeg and ffprobe)"`
	// Format to convert the audio to when -x is used. (currently supported: best (default), aac,
	// alac, flac, m4a, mp3, opus, vorbis, wav). You can specify multiple rules using similar
	// syntax as --remux-video
	AudioFormat *string `json:"audio_format,omitempty" id:"audioformat" jsonschema:"title=AudioFormat" jsonschema_extras:"uid=audioformat" jsonschema_description:"Format to convert the audio to when -x is used. (currently supported: best (default), aac, alac, flac, m4a, mp3, opus, vorbis, wav). You can specify multiple rules using similar syntax as --remux-video"`
	// Specify ffmpeg audio quality to use when converting the audio with -x. Insert a value
	// between 0 (best) and 10 (worst) for VBR or a specific bitrate like 128K (default 5)
	AudioQuality *string `json:"audio_quality,omitempty" id:"audioquality" jsonschema:"title=AudioQuality" jsonschema_extras:"uid=audioquality" jsonschema_description:"Specify ffmpeg audio quality to use when converting the audio with -x. Insert a value between 0 (best) and 10 (worst) for VBR or a specific bitrate like 128K (default 5)"`
	// Remux the video into another container if necessary (currently supported: avi, flv, gif,
	// mkv, mov, mp4, webm, aac, aiff, alac, flac, m4a, mka, mp3, ogg, opus, vorbis, wav). If the
	// target container does not support the video/audio codec, remuxing will fail. You can
	// specify multiple rules; e.g. "aac>m4a/mov>mp4/mkv" will remux aac to m4a, mov to mp4 and
	// anything else to mkv
	RemuxVideo *string `json:"remux_video,omitempty" id:"remuxvideo" jsonschema:"title=RemuxVideo" jsonschema_extras:"uid=remuxvideo" jsonschema_description:"Remux the video into another container if necessary (currently supported: avi, flv, gif, mkv, mov, mp4, webm, aac, aiff, alac, flac, m4a, mka, mp3, ogg, opus, vorbis, wav). If the target container does not support the video/audio codec, remuxing will fail. You can specify multiple rules; e.g. \"aac>m4a/mov>mp4/mkv\" will remux aac to m4a, mov to mp4 and anything else to mkv"`
	// Re-encode the video into another format if necessary. The syntax and supported formats are
	// the same as --remux-video
	RecodeVideo *string `json:"recode_video,omitempty" id:"recodevideo" jsonschema:"title=RecodeVideo" jsonschema_extras:"uid=recodevideo" jsonschema_description:"Re-encode the video into another format if necessary. The syntax and supported formats are the same as --remux-video"`
	// Give these arguments to the postprocessors. Specify the postprocessor/executable name and
	// the arguments separated by a colon ":" to give the argument to the specified
	// postprocessor/executable. Supported PP are: Merger, ModifyChapters, SplitChapters,
	// ExtractAudio, VideoRemuxer, VideoConvertor, Metadata, EmbedSubtitle, EmbedThumbnail,
	// SubtitlesConvertor, ThumbnailsConvertor, FixupStretched, FixupM4a, FixupM3u8,
	// FixupTimestamp and FixupDuration. The supported executables are: AtomicParsley, FFmpeg and
	// FFprobe. You can also specify "PP+EXE:ARGS" to give the arguments to the specified
	// executable only when being used by the specified postprocessor. Additionally, for
	// ffmpeg/ffprobe, "_i"/"_o" can be appended to the prefix optionally followed by a number to
	// pass the argument before the specified input/output file, e.g. --ppa "Merger+ffmpeg_i1:-v
	// quiet". You can use this option multiple times to give different arguments to different
	// postprocessors.
	PostProcessorArgs []string `json:"postprocessor_args,omitempty" id:"postprocessor_args" jsonschema:"title=PostProcessorArgs" jsonschema_extras:"uid=postprocessor_args" jsonschema_description:"Give these arguments to the postprocessors. Specify the postprocessor/executable name and the arguments separated by a colon \":\" to give the argument to the specified postprocessor/executable. Supported PP are: Merger, ModifyChapters, SplitChapters, ExtractAudio, VideoRemuxer, VideoConvertor, Metadata, EmbedSubtitle, EmbedThumbnail, SubtitlesConvertor, ThumbnailsConvertor, FixupStretched, FixupM4a, FixupM3u8, FixupTimestamp and FixupDuration. The supported executables are: AtomicParsley, FFmpeg and FFprobe. You can also specify \"PP+EXE:ARGS\" to give the arguments to the specified executable only when being used by the specified postprocessor. Additionally, for ffmpeg/ffprobe, \"_i\"/\"_o\" can be appended to the prefix optionally followed by a number to pass the argument before the specified input/output file, e.g. --ppa \"Merger+ffmpeg_i1:-v quiet\". You can use this option multiple times to give different arguments to different postprocessors."`
	// Keep the intermediate video file on disk after post-processing
	KeepVideo *bool `json:"keep_video,omitempty" id:"keepvideo" jsonschema:"title=KeepVideo" jsonschema_extras:"uid=keepvideo" jsonschema_description:"Keep the intermediate video file on disk after post-processing"`
	// Delete the intermediate video file after post-processing (default)
	NoKeepVideo *bool `json:"no_keep_video,omitempty" id:"keepvideo" jsonschema:"title=NoKeepVideo" jsonschema_extras:"uid=keepvideo" jsonschema_description:"Delete the intermediate video file after post-processing (default)"`
	// Overwrite post-processed files (default)
	PostOverwrites *bool `json:"post_overwrites,omitempty" id:"nopostoverwrites" jsonschema:"title=PostOverwrites" jsonschema_extras:"uid=nopostoverwrites" jsonschema_description:"Overwrite post-processed files (default)"`
	// Do not overwrite post-processed files
	NoPostOverwrites *bool `json:"no_post_overwrites,omitempty" id:"nopostoverwrites" jsonschema:"title=NoPostOverwrites" jsonschema_extras:"uid=nopostoverwrites" jsonschema_description:"Do not overwrite post-processed files"`
	// Embed subtitles in the video (only for mp4, webm and mkv videos)
	EmbedSubs *bool `json:"embed_subs,omitempty" id:"embedsubtitles" jsonschema:"title=EmbedSubs" jsonschema_extras:"uid=embedsubtitles" jsonschema_description:"Embed subtitles in the video (only for mp4, webm and mkv videos)"`
	// Do not embed subtitles (default)
	NoEmbedSubs *bool `json:"no_embed_subs,omitempty" id:"embedsubtitles" jsonschema:"title=NoEmbedSubs" jsonschema_extras:"uid=embedsubtitles" jsonschema_description:"Do not embed subtitles (default)"`
	// Embed thumbnail in the video as cover art
	EmbedThumbnail *bool `json:"embed_thumbnail,omitempty" id:"embedthumbnail" jsonschema:"title=EmbedThumbnail" jsonschema_extras:"uid=embedthumbnail" jsonschema_description:"Embed thumbnail in the video as cover art"`
	// Do not embed thumbnail (default)
	NoEmbedThumbnail *bool `json:"no_embed_thumbnail,omitempty" id:"embedthumbnail" jsonschema:"title=NoEmbedThumbnail" jsonschema_extras:"uid=embedthumbnail" jsonschema_description:"Do not embed thumbnail (default)"`
	// Embed metadata to the video file. Also embeds chapters/infojson if present unless
	// --no-embed-chapters/--no-embed-info-json are used
	EmbedMetadata *bool `json:"embed_metadata,omitempty" id:"addmetadata" jsonschema:"title=EmbedMetadata" jsonschema_extras:"uid=addmetadata" jsonschema_description:"Embed metadata to the video file. Also embeds chapters/infojson if present unless --no-embed-chapters/--no-embed-info-json are used"`
	// Do not add metadata to file (default)
	NoEmbedMetadata *bool `json:"no_embed_metadata,omitempty" id:"addmetadata" jsonschema:"title=NoEmbedMetadata" jsonschema_extras:"uid=addmetadata" jsonschema_description:"Do not add metadata to file (default)"`
	// Add chapter markers to the video file
	EmbedChapters *bool `json:"embed_chapters,omitempty" id:"addchapters" jsonschema:"title=EmbedChapters" jsonschema_extras:"uid=addchapters" jsonschema_description:"Add chapter markers to the video file"`
	// Do not add chapter markers (default)
	NoEmbedChapters *bool `json:"no_embed_chapters,omitempty" id:"addchapters" jsonschema:"title=NoEmbedChapters" jsonschema_extras:"uid=addchapters" jsonschema_description:"Do not add chapter markers (default)"`
	// Embed the infojson as an attachment to mkv/mka video files
	EmbedInfoJSON *bool `json:"embed_info_json,omitempty" id:"embed_infojson" jsonschema:"title=EmbedInfoJSON" jsonschema_extras:"uid=embed_infojson" jsonschema_description:"Embed the infojson as an attachment to mkv/mka video files"`
	// Do not embed the infojson as an attachment to the video file
	NoEmbedInfoJSON   *bool   `json:"no_embed_info_json,omitempty" id:"embed_infojson" jsonschema:"title=NoEmbedInfoJSON" jsonschema_extras:"uid=embed_infojson" jsonschema_description:"Do not embed the infojson as an attachment to the video file"`
	MetadataFromTitle *string `json:"metadata_from_title,omitempty" id:"metafromtitle" jsonschema:"title=MetadataFromTitle" jsonschema_extras:"uid=metafromtitle" jsonschema_description:""`
	// Parse additional metadata like title/artist from other fields; see "MODIFYING METADATA"
	// for details. Supported values of "WHEN" are the same as that of --use-postprocessor
	// (default: pre_process)
	ParseMetadata *string `json:"parse_metadata,omitempty" id:"parse_metadata" jsonschema:"title=ParseMetadata" jsonschema_extras:"uid=parse_metadata" jsonschema_description:"Parse additional metadata like title/artist from other fields; see \"MODIFYING METADATA\" for details. Supported values of \"WHEN\" are the same as that of --use-postprocessor (default: pre_process)"`
	// Replace text in a metadata field using the given regex. This option can be used multiple
	// times. Supported values of "WHEN" are the same as that of --use-postprocessor (default:
	// pre_process)
	ReplaceInMetadata []*FlagReplaceInMetadata `json:"replace_in_metadata,omitempty" id:"parse_metadata" jsonschema:"title=ReplaceInMetadata" jsonschema_extras:"uid=parse_metadata" jsonschema_description:"Replace text in a metadata field using the given regex. This option can be used multiple times. Supported values of \"WHEN\" are the same as that of --use-postprocessor (default: pre_process)"`
	// Write metadata to the video file's xattrs (using Dublin Core and XDG standards)
	Xattrs *bool `json:"xattrs,omitempty" id:"xattrs" jsonschema:"title=Xattrs" jsonschema_extras:"uid=xattrs" jsonschema_description:"Write metadata to the video file's xattrs (using Dublin Core and XDG standards)"`
	// Concatenate videos in a playlist. One of "never", "always", or "multi_video" (default;
	// only when the videos form a single show). All the video files must have the same codecs
	// and number of streams to be concatenable. The "pl_video:" prefix can be used with
	// "--paths" and "--output" to set the output filename for the concatenated files. See
	// "OUTPUT TEMPLATE" for details
	ConcatPlaylist *ConcatPlaylistOption `json:"concat_playlist,omitempty" id:"concat_playlist" jsonschema:"enum=never,enum=always,enum=multi_video,title=ConcatPlaylist" jsonschema_extras:"uid=concat_playlist" jsonschema_description:"Concatenate videos in a playlist. One of \"never\", \"always\", or \"multi_video\" (default; only when the videos form a single show). All the video files must have the same codecs and number of streams to be concatenable. The \"pl_video:\" prefix can be used with \"--paths\" and \"--output\" to set the output filename for the concatenated files. See \"OUTPUT TEMPLATE\" for details"`
	// Automatically correct known faults of the file. One of never (do nothing), warn (only emit
	// a warning), detect_or_warn (the default; fix the file if we can, warn otherwise), force
	// (try fixing even if the file already exists)
	Fixup *FixupOption `json:"fixup,omitempty" id:"fixup" jsonschema:"enum=never,enum=ignore,enum=warn,enum=detect_or_warn,enum=force,title=Fixup" jsonschema_extras:"uid=fixup" jsonschema_description:"Automatically correct known faults of the file. One of never (do nothing), warn (only emit a warning), detect_or_warn (the default; fix the file if we can, warn otherwise), force (try fixing even if the file already exists)"`
	// Location of the ffmpeg binary; either the path to the binary or its containing directory
	FFmpegLocation *string `json:"ffmpeg_location,omitempty" id:"ffmpeg_location" jsonschema:"title=FFmpegLocation" jsonschema_extras:"uid=ffmpeg_location" jsonschema_description:"Location of the ffmpeg binary; either the path to the binary or its containing directory"`
	// Execute a command, optionally prefixed with when to execute it, separated by a ":".
	// Supported values of "WHEN" are the same as that of --use-postprocessor (default:
	// after_move). The same syntax as the output template can be used to pass any field as
	// arguments to the command. If no fields are passed, %(filepath,_filename|)q is appended to
	// the end of the command. This option can be used multiple times
	Exec []string `json:"exec,omitempty" id:"exec_cmd" jsonschema:"title=Exec" jsonschema_extras:"uid=exec_cmd" jsonschema_description:"Execute a command, optionally prefixed with when to execute it, separated by a \":\". Supported values of \"WHEN\" are the same as that of --use-postprocessor (default: after_move). The same syntax as the output template can be used to pass any field as arguments to the command. If no fields are passed, %(filepath,_filename|)q is appended to the end of the command. This option can be used multiple times"`
	// Remove any previously defined --exec
	NoExec               *bool   `json:"no_exec,omitempty" id:"exec_cmd" jsonschema:"title=NoExec" jsonschema_extras:"uid=exec_cmd" jsonschema_description:"Remove any previously defined --exec"`
	ExecBeforeDownload   *string `json:"exec_before_download,omitempty" id:"exec_before_dl_cmd" jsonschema:"title=ExecBeforeDownload" jsonschema_extras:"uid=exec_before_dl_cmd" jsonschema_description:""`
	NoExecBeforeDownload *bool   `json:"no_exec_before_download,omitempty" id:"exec_before_dl_cmd" jsonschema:"title=NoExecBeforeDownload" jsonschema_extras:"uid=exec_before_dl_cmd" jsonschema_description:""`
	// Convert the subtitles to another format (currently supported: ass, lrc, srt, vtt). Use
	// "--convert-subs none" to disable conversion (default)
	ConvertSubs *string `json:"convert_subs,omitempty" id:"convertsubtitles" jsonschema:"title=ConvertSubs" jsonschema_extras:"uid=convertsubtitles" jsonschema_description:"Convert the subtitles to another format (currently supported: ass, lrc, srt, vtt). Use \"--convert-subs none\" to disable conversion (default)"`
	// Convert the thumbnails to another format (currently supported: jpg, png, webp). You can
	// specify multiple rules using similar syntax as "--remux-video". Use "--convert-thumbnails
	// none" to disable conversion (default)
	ConvertThumbnails *string `json:"convert_thumbnails,omitempty" id:"convertthumbnails" jsonschema:"title=ConvertThumbnails" jsonschema_extras:"uid=convertthumbnails" jsonschema_description:"Convert the thumbnails to another format (currently supported: jpg, png, webp). You can specify multiple rules using similar syntax as \"--remux-video\". Use \"--convert-thumbnails none\" to disable conversion (default)"`
	// Split video into multiple files based on internal chapters. The "chapter:" prefix can be
	// used with "--paths" and "--output" to set the output filename for the split files. See
	// "OUTPUT TEMPLATE" for details
	SplitChapters *bool `json:"split_chapters,omitempty" id:"split_chapters" jsonschema:"title=SplitChapters" jsonschema_extras:"uid=split_chapters" jsonschema_description:"Split video into multiple files based on internal chapters. The \"chapter:\" prefix can be used with \"--paths\" and \"--output\" to set the output filename for the split files. See \"OUTPUT TEMPLATE\" for details"`
	// Do not split video based on chapters (default)
	NoSplitChapters *bool `json:"no_split_chapters,omitempty" id:"split_chapters" jsonschema:"title=NoSplitChapters" jsonschema_extras:"uid=split_chapters" jsonschema_description:"Do not split video based on chapters (default)"`
	// Remove chapters whose title matches the given regular expression. The syntax is the same
	// as --download-sections. This option can be used multiple times
	RemoveChapters []string `json:"remove_chapters,omitempty" id:"remove_chapters" jsonschema:"title=RemoveChapters" jsonschema_extras:"uid=remove_chapters" jsonschema_description:"Remove chapters whose title matches the given regular expression. The syntax is the same as --download-sections. This option can be used multiple times"`
	// Do not remove any chapters from the file (default)
	NoRemoveChapters *bool `json:"no_remove_chapters,omitempty" id:"remove_chapters" jsonschema:"title=NoRemoveChapters" jsonschema_extras:"uid=remove_chapters" jsonschema_description:"Do not remove any chapters from the file (default)"`
	// Force keyframes at cuts when downloading/splitting/removing sections. This is slow due to
	// needing a re-encode, but the resulting video may have fewer artifacts around the cuts
	ForceKeyframesAtCuts *bool `json:"force_keyframes_at_cuts,omitempty" id:"force_keyframes_at_cuts" jsonschema:"title=ForceKeyframesAtCuts" jsonschema_extras:"uid=force_keyframes_at_cuts" jsonschema_description:"Force keyframes at cuts when downloading/splitting/removing sections. This is slow due to needing a re-encode, but the resulting video may have fewer artifacts around the cuts"`
	// Do not force keyframes around the chapters when cutting/splitting (default)
	NoForceKeyframesAtCuts *bool `json:"no_force_keyframes_at_cuts,omitempty" id:"force_keyframes_at_cuts" jsonschema:"title=NoForceKeyframesAtCuts" jsonschema_extras:"uid=force_keyframes_at_cuts" jsonschema_description:"Do not force keyframes around the chapters when cutting/splitting (default)"`
	// The (case-sensitive) name of plugin postprocessors to be enabled, and (optionally)
	// arguments to be passed to it, separated by a colon ":". ARGS are a semicolon ";" delimited
	// list of NAME=VALUE. The "when" argument determines when the postprocessor is invoked. It
	// can be one of "pre_process" (after video extraction), "after_filter" (after video passes
	// filter), "video" (after --format; before --print/--output), "before_dl" (before each video
	// download), "post_process" (after each video download; default), "after_move" (after moving
	// the video file to its final location), "after_video" (after downloading and processing all
	// formats of a video), or "playlist" (at end of playlist). This option can be used multiple
	// times to add different postprocessors
	UsePostProcessor []string `json:"use_postprocessor,omitempty" id:"add_postprocessors" jsonschema:"title=UsePostProcessor" jsonschema_extras:"uid=add_postprocessors" jsonschema_description:"The (case-sensitive) name of plugin postprocessors to be enabled, and (optionally) arguments to be passed to it, separated by a colon \":\". ARGS are a semicolon \";\" delimited list of NAME=VALUE. The \"when\" argument determines when the postprocessor is invoked. It can be one of \"pre_process\" (after video extraction), \"after_filter\" (after video passes filter), \"video\" (after --format; before --print/--output), \"before_dl\" (before each video download), \"post_process\" (after each video download; default), \"after_move\" (after moving the video file to its final location), \"after_video\" (after downloading and processing all formats of a video), or \"playlist\" (at end of playlist). This option can be used multiple times to add different postprocessors"`
}

type FlagReplaceInMetadata struct {
	Fields  string `json:"fields,omitempty" jsonschema:"title=ReplaceInMetadata" jsonschema_extras:"uid=parse_metadata" jsonschema_description:"Replace text in a metadata field using the given regex. This option can be used multiple times. Supported values of \"WHEN\" are the same as that of --use-postprocessor (default: pre_process)"`
	Regex   string `json:"regex,omitempty" jsonschema:"title=ReplaceInMetadata" jsonschema_extras:"uid=parse_metadata" jsonschema_description:"Replace text in a metadata field using the given regex. This option can be used multiple times. Supported values of \"WHEN\" are the same as that of --use-postprocessor (default: pre_process)"`
	Replace string `json:"replace,omitempty" jsonschema:"title=ReplaceInMetadata" jsonschema_extras:"uid=parse_metadata" jsonschema_description:"Replace text in a metadata field using the given regex. This option can be used multiple times. Supported values of \"WHEN\" are the same as that of --use-postprocessor (default: pre_process)"`
}

// Validate ensures all flags have appropriate values. If there are validation-specific
// errors, they will be returned as a [ErrMultipleJSONParsingFlags] error.
func (g *FlagsPostProcessing) Validate() error {
	if g == nil {
		return nil
	}

	var validationErrs []*ErrJSONParsingFlag
	if g.ConcatPlaylist != nil {
		if !slices.Contains(AllConcatPlaylistOptions, *g.ConcatPlaylist) {
			validationErrs = append(validationErrs, &ErrJSONParsingFlag{
				JSONPath: "post_processing.concat_playlist",
				Flag:     "--concat-playlist",
				ID:       "concat_playlist",
				Err: fmt.Errorf(
					"invalid value for post_processing.concat_playlist: %q (expected one of: %v)",
					*g.ConcatPlaylist,
					AllConcatPlaylistOptions,
				),
			})
		}
	}
	if g.Fixup != nil {
		if !slices.Contains(AllFixupOptions, *g.Fixup) {
			validationErrs = append(validationErrs, &ErrJSONParsingFlag{
				JSONPath: "post_processing.fixup",
				Flag:     "--fixup",
				ID:       "fixup",
				Err: fmt.Errorf(
					"invalid value for post_processing.fixup: %q (expected one of: %v)",
					*g.Fixup,
					AllFixupOptions,
				),
			})
		}
	}

	duplicates := g.ToFlags().Duplicates()
	for _, duplicate := range duplicates {
		validationErrs = append(validationErrs, &ErrJSONParsingFlag{
			JSONPath: "post_processing." + duplicate.ID,
			Flag:     duplicate.Flag,
			ID:       duplicate.ID,
			Err:      fmt.Errorf("duplicate flag (with conflicting ID %q) found: %v", duplicate.ID, duplicate.Flag),
		})
	}

	if len(validationErrs) > 0 {
		return &ErrMultipleJSONParsingFlags{Errors: validationErrs}
	}
	return nil
}

// ToFlags returns the generated flags based off the provided configuration. [FlagsPostProcessing.Validate]
// should be called first.
func (g *FlagsPostProcessing) ToFlags() (flags Flags) {
	if g == nil {
		return flags
	}
	if g.ExtractAudio != nil && *g.ExtractAudio {
		flags = append(flags, &Flag{ID: "extractaudio", Flag: "--extract-audio", Args: nil})
	}
	if g.AudioFormat != nil {
		flags = append(flags, &Flag{ID: "audioformat", Flag: "--audio-format", Args: []any{*g.AudioFormat}})
	}
	if g.AudioQuality != nil {
		flags = append(flags, &Flag{ID: "audioquality", Flag: "--audio-quality", Args: []any{*g.AudioQuality}})
	}
	if g.RemuxVideo != nil {
		flags = append(flags, &Flag{ID: "remuxvideo", Flag: "--remux-video", Args: []any{*g.RemuxVideo}})
	}
	if g.RecodeVideo != nil {
		flags = append(flags, &Flag{ID: "recodevideo", Flag: "--recode-video", Args: []any{*g.RecodeVideo}})
	}
	for _, v := range g.PostProcessorArgs {
		flags = append(flags, &Flag{ID: "postprocessor_args", Flag: "--postprocessor-args", AllowsMultiple: true, Args: []any{v}})
	}
	if g.KeepVideo != nil && *g.KeepVideo {
		flags = append(flags, &Flag{ID: "keepvideo", Flag: "--keep-video", Args: nil})
	}
	if g.NoKeepVideo != nil && *g.NoKeepVideo {
		flags = append(flags, &Flag{ID: "keepvideo", Flag: "--no-keep-video", Args: nil})
	}
	if g.PostOverwrites != nil && *g.PostOverwrites {
		flags = append(flags, &Flag{ID: "nopostoverwrites", Flag: "--post-overwrites", Args: nil})
	}
	if g.NoPostOverwrites != nil && *g.NoPostOverwrites {
		flags = append(flags, &Flag{ID: "nopostoverwrites", Flag: "--no-post-overwrites", Args: nil})
	}
	if g.EmbedSubs != nil && *g.EmbedSubs {
		flags = append(flags, &Flag{ID: "embedsubtitles", Flag: "--embed-subs", Args: nil})
	}
	if g.NoEmbedSubs != nil && *g.NoEmbedSubs {
		flags = append(flags, &Flag{ID: "embedsubtitles", Flag: "--no-embed-subs", Args: nil})
	}
	if g.EmbedThumbnail != nil && *g.EmbedThumbnail {
		flags = append(flags, &Flag{ID: "embedthumbnail", Flag: "--embed-thumbnail", Args: nil})
	}
	if g.NoEmbedThumbnail != nil && *g.NoEmbedThumbnail {
		flags = append(flags, &Flag{ID: "embedthumbnail", Flag: "--no-embed-thumbnail", Args: nil})
	}
	if g.EmbedMetadata != nil && *g.EmbedMetadata {
		flags = append(flags, &Flag{ID: "addmetadata", Flag: "--embed-metadata", Args: nil})
	}
	if g.NoEmbedMetadata != nil && *g.NoEmbedMetadata {
		flags = append(flags, &Flag{ID: "addmetadata", Flag: "--no-embed-metadata", Args: nil})
	}
	if g.EmbedChapters != nil && *g.EmbedChapters {
		flags = append(flags, &Flag{ID: "addchapters", Flag: "--embed-chapters", Args: nil})
	}
	if g.NoEmbedChapters != nil && *g.NoEmbedChapters {
		flags = append(flags, &Flag{ID: "addchapters", Flag: "--no-embed-chapters", Args: nil})
	}
	if g.EmbedInfoJSON != nil && *g.EmbedInfoJSON {
		flags = append(flags, &Flag{ID: "embed_infojson", Flag: "--embed-info-json", Args: nil})
	}
	if g.NoEmbedInfoJSON != nil && *g.NoEmbedInfoJSON {
		flags = append(flags, &Flag{ID: "embed_infojson", Flag: "--no-embed-info-json", Args: nil})
	}
	if g.MetadataFromTitle != nil {
		flags = append(flags, &Flag{ID: "metafromtitle", Flag: "--metadata-from-title", Args: []any{*g.MetadataFromTitle}})
	}
	if g.ParseMetadata != nil {
		flags = append(flags, &Flag{ID: "parse_metadata", Flag: "--parse-metadata", Args: []any{*g.ParseMetadata}})
	}
	for _, v := range g.ReplaceInMetadata {
		flags = append(flags, &Flag{ID: "parse_metadata", Flag: "--replace-in-metadata", AllowsMultiple: true, Args: []any{v.Fields, v.Regex, v.Replace}})
	}
	if g.Xattrs != nil && *g.Xattrs {
		flags = append(flags, &Flag{ID: "xattrs", Flag: "--xattrs", Args: nil})
	}
	if g.ConcatPlaylist != nil {
		flags = append(flags, &Flag{ID: "concat_playlist", Flag: "--concat-playlist", Args: []any{string(*g.ConcatPlaylist)}})
	}
	if g.Fixup != nil {
		flags = append(flags, &Flag{ID: "fixup", Flag: "--fixup", Args: []any{string(*g.Fixup)}})
	}
	if g.FFmpegLocation != nil {
		flags = append(flags, &Flag{ID: "ffmpeg_location", Flag: "--ffmpeg-location", Args: []any{*g.FFmpegLocation}})
	}
	for _, v := range g.Exec {
		flags = append(flags, &Flag{ID: "exec_cmd", Flag: "--exec", AllowsMultiple: true, Args: []any{v}})
	}
	if g.NoExec != nil && *g.NoExec {
		flags = append(flags, &Flag{ID: "exec_cmd", Flag: "--no-exec", Args: nil})
	}
	if g.ExecBeforeDownload != nil {
		flags = append(flags, &Flag{ID: "exec_before_dl_cmd", Flag: "--exec-before-download", Args: []any{*g.ExecBeforeDownload}})
	}
	if g.NoExecBeforeDownload != nil && *g.NoExecBeforeDownload {
		flags = append(flags, &Flag{ID: "exec_before_dl_cmd", Flag: "--no-exec-before-download", Args: nil})
	}
	if g.ConvertSubs != nil {
		flags = append(flags, &Flag{ID: "convertsubtitles", Flag: "--convert-subs", Args: []any{*g.ConvertSubs}})
	}
	if g.ConvertThumbnails != nil {
		flags = append(flags, &Flag{ID: "convertthumbnails", Flag: "--convert-thumbnails", Args: []any{*g.ConvertThumbnails}})
	}
	if g.SplitChapters != nil && *g.SplitChapters {
		flags = append(flags, &Flag{ID: "split_chapters", Flag: "--split-chapters", Args: nil})
	}
	if g.NoSplitChapters != nil && *g.NoSplitChapters {
		flags = append(flags, &Flag{ID: "split_chapters", Flag: "--no-split-chapters", Args: nil})
	}
	for _, v := range g.RemoveChapters {
		flags = append(flags, &Flag{ID: "remove_chapters", Flag: "--remove-chapters", AllowsMultiple: true, Args: []any{v}})
	}
	if g.NoRemoveChapters != nil && *g.NoRemoveChapters {
		flags = append(flags, &Flag{ID: "remove_chapters", Flag: "--no-remove-chapters", Args: nil})
	}
	if g.ForceKeyframesAtCuts != nil && *g.ForceKeyframesAtCuts {
		flags = append(flags, &Flag{ID: "force_keyframes_at_cuts", Flag: "--force-keyframes-at-cuts", Args: nil})
	}
	if g.NoForceKeyframesAtCuts != nil && *g.NoForceKeyframesAtCuts {
		flags = append(flags, &Flag{ID: "force_keyframes_at_cuts", Flag: "--no-force-keyframes-at-cuts", Args: nil})
	}
	for _, v := range g.UsePostProcessor {
		flags = append(flags, &Flag{ID: "add_postprocessors", Flag: "--use-postprocessor", AllowsMultiple: true, Args: []any{v}})
	}
	return flags
}

type FlagsSponsorBlock struct {
	// SponsorBlock categories to create chapters for, separated by commas. Available categories
	// are sponsor, intro, outro, selfpromo, preview, filler, interaction, music_offtopic, hook,
	// poi_highlight, chapter, all and default (=all). You can prefix the category with a "-" to
	// exclude it. See [1] for descriptions of the categories. E.g. --sponsorblock-mark
	// all,-preview [1] https://wiki.sponsor.ajay.app/w/Segment_Categories
	SponsorblockMark *string `json:"sponsorblock_mark,omitempty" id:"sponsorblock_mark" jsonschema:"title=SponsorblockMark" jsonschema_extras:"uid=sponsorblock_mark" jsonschema_description:"SponsorBlock categories to create chapters for, separated by commas. Available categories are sponsor, intro, outro, selfpromo, preview, filler, interaction, music_offtopic, hook, poi_highlight, chapter, all and default (=all). You can prefix the category with a \"-\" to exclude it. See [1] for descriptions of the categories. E.g. --sponsorblock-mark all,-preview [1] https://wiki.sponsor.ajay.app/w/Segment_Categories"`
	// SponsorBlock categories to be removed from the video file, separated by commas. If a
	// category is present in both mark and remove, remove takes precedence. The syntax and
	// available categories are the same as for --sponsorblock-mark except that "default" refers
	// to "all,-filler" and poi_highlight, chapter are not available
	SponsorblockRemove *string `json:"sponsorblock_remove,omitempty" id:"sponsorblock_remove" jsonschema:"title=SponsorblockRemove" jsonschema_extras:"uid=sponsorblock_remove" jsonschema_description:"SponsorBlock categories to be removed from the video file, separated by commas. If a category is present in both mark and remove, remove takes precedence. The syntax and available categories are the same as for --sponsorblock-mark except that \"default\" refers to \"all,-filler\" and poi_highlight, chapter are not available"`
	// An output template for the title of the SponsorBlock chapters created by
	// --sponsorblock-mark. The only available fields are start_time, end_time, category,
	// categories, name, category_names. Defaults to "[SponsorBlock]: %(category_names)l"
	SponsorblockChapterTitle *string `json:"sponsorblock_chapter_title,omitempty" id:"sponsorblock_chapter_title" jsonschema:"title=SponsorblockChapterTitle" jsonschema_extras:"uid=sponsorblock_chapter_title" jsonschema_description:"An output template for the title of the SponsorBlock chapters created by --sponsorblock-mark. The only available fields are start_time, end_time, category, categories, name, category_names. Defaults to \"[SponsorBlock]: %(category_names)l\""`
	// Disable both --sponsorblock-mark and --sponsorblock-remove
	NoSponsorblock *bool `json:"no_sponsorblock,omitempty" id:"no_sponsorblock" jsonschema:"title=NoSponsorblock" jsonschema_extras:"uid=no_sponsorblock" jsonschema_description:"Disable both --sponsorblock-mark and --sponsorblock-remove"`
	// SponsorBlock API location, defaults to https://sponsor.ajay.app
	SponsorblockAPI *string `json:"sponsorblock_api,omitempty" id:"sponsorblock_api" jsonschema:"title=SponsorblockAPI" jsonschema_extras:"uid=sponsorblock_api" jsonschema_description:"SponsorBlock API location, defaults to https://sponsor.ajay.app"`
}

// Validate ensures all flags have appropriate values. If there are validation-specific
// errors, they will be returned as a [ErrMultipleJSONParsingFlags] error.
func (g *FlagsSponsorBlock) Validate() error {
	if g == nil {
		return nil
	}

	var validationErrs []*ErrJSONParsingFlag

	duplicates := g.ToFlags().Duplicates()
	for _, duplicate := range duplicates {
		validationErrs = append(validationErrs, &ErrJSONParsingFlag{
			JSONPath: "sponsor_block." + duplicate.ID,
			Flag:     duplicate.Flag,
			ID:       duplicate.ID,
			Err:      fmt.Errorf("duplicate flag (with conflicting ID %q) found: %v", duplicate.ID, duplicate.Flag),
		})
	}

	if len(validationErrs) > 0 {
		return &ErrMultipleJSONParsingFlags{Errors: validationErrs}
	}
	return nil
}

// ToFlags returns the generated flags based off the provided configuration. [FlagsSponsorBlock.Validate]
// should be called first.
func (g *FlagsSponsorBlock) ToFlags() (flags Flags) {
	if g == nil {
		return flags
	}
	if g.SponsorblockMark != nil {
		flags = append(flags, &Flag{ID: "sponsorblock_mark", Flag: "--sponsorblock-mark", Args: []any{*g.SponsorblockMark}})
	}
	if g.SponsorblockRemove != nil {
		flags = append(flags, &Flag{ID: "sponsorblock_remove", Flag: "--sponsorblock-remove", Args: []any{*g.SponsorblockRemove}})
	}
	if g.SponsorblockChapterTitle != nil {
		flags = append(flags, &Flag{ID: "sponsorblock_chapter_title", Flag: "--sponsorblock-chapter-title", Args: []any{*g.SponsorblockChapterTitle}})
	}
	if g.NoSponsorblock != nil && *g.NoSponsorblock {
		flags = append(flags, &Flag{ID: "no_sponsorblock", Flag: "--no-sponsorblock", Args: nil})
	}
	if g.SponsorblockAPI != nil {
		flags = append(flags, &Flag{ID: "sponsorblock_api", Flag: "--sponsorblock-api", Args: []any{*g.SponsorblockAPI}})
	}
	return flags
}

type FlagsExtractor struct {
	// Number of retries for known extractor errors (default is 3), or "infinite"
	ExtractorRetries *string `json:"extractor_retries,omitempty" id:"extractor_retries" jsonschema:"title=ExtractorRetries" jsonschema_extras:"uid=extractor_retries" jsonschema_description:"Number of retries for known extractor errors (default is 3), or \"infinite\""`
	// Process dynamic DASH manifests (default)
	AllowDynamicMPD *bool `json:"allow_dynamic_mpd,omitempty" id:"dynamic_mpd" jsonschema:"title=AllowDynamicMPD" jsonschema_extras:"uid=dynamic_mpd" jsonschema_description:"Process dynamic DASH manifests (default)"`
	// Do not process dynamic DASH manifests
	IgnoreDynamicMPD *bool `json:"ignore_dynamic_mpd,omitempty" id:"dynamic_mpd" jsonschema:"title=IgnoreDynamicMPD" jsonschema_extras:"uid=dynamic_mpd" jsonschema_description:"Do not process dynamic DASH manifests"`
	// Split HLS playlists to different formats at discontinuities such as ad breaks
	HLSSplitDiscontinuity *bool `json:"hls_split_discontinuity,omitempty" id:"hls_split_discontinuity" jsonschema:"title=HLSSplitDiscontinuity" jsonschema_extras:"uid=hls_split_discontinuity" jsonschema_description:"Split HLS playlists to different formats at discontinuities such as ad breaks"`
	// Do not split HLS playlists into different formats at discontinuities such as ad breaks
	// (default)
	NoHLSSplitDiscontinuity *bool `json:"no_hls_split_discontinuity,omitempty" id:"hls_split_discontinuity" jsonschema:"title=NoHLSSplitDiscontinuity" jsonschema_extras:"uid=hls_split_discontinuity" jsonschema_description:"Do not split HLS playlists into different formats at discontinuities such as ad breaks (default)"`
	// Pass ARGS arguments to the IE_KEY extractor. See "EXTRACTOR ARGUMENTS" for details. You
	// can use this option multiple times to give arguments for different extractors
	ExtractorArgs []string `json:"extractor_args,omitempty" id:"extractor_args" jsonschema:"title=ExtractorArgs" jsonschema_extras:"uid=extractor_args" jsonschema_description:"Pass ARGS arguments to the IE_KEY extractor. See \"EXTRACTOR ARGUMENTS\" for details. You can use this option multiple times to give arguments for different extractors"`
}

// Validate ensures all flags have appropriate values. If there are validation-specific
// errors, they will be returned as a [ErrMultipleJSONParsingFlags] error.
func (g *FlagsExtractor) Validate() error {
	if g == nil {
		return nil
	}

	var validationErrs []*ErrJSONParsingFlag

	duplicates := g.ToFlags().Duplicates()
	for _, duplicate := range duplicates {
		validationErrs = append(validationErrs, &ErrJSONParsingFlag{
			JSONPath: "extractor." + duplicate.ID,
			Flag:     duplicate.Flag,
			ID:       duplicate.ID,
			Err:      fmt.Errorf("duplicate flag (with conflicting ID %q) found: %v", duplicate.ID, duplicate.Flag),
		})
	}

	if len(validationErrs) > 0 {
		return &ErrMultipleJSONParsingFlags{Errors: validationErrs}
	}
	return nil
}

// ToFlags returns the generated flags based off the provided configuration. [FlagsExtractor.Validate]
// should be called first.
func (g *FlagsExtractor) ToFlags() (flags Flags) {
	if g == nil {
		return flags
	}
	if g.ExtractorRetries != nil {
		flags = append(flags, &Flag{ID: "extractor_retries", Flag: "--extractor-retries", Args: []any{*g.ExtractorRetries}})
	}
	if g.AllowDynamicMPD != nil && *g.AllowDynamicMPD {
		flags = append(flags, &Flag{ID: "dynamic_mpd", Flag: "--allow-dynamic-mpd", Args: nil})
	}
	if g.IgnoreDynamicMPD != nil && *g.IgnoreDynamicMPD {
		flags = append(flags, &Flag{ID: "dynamic_mpd", Flag: "--ignore-dynamic-mpd", Args: nil})
	}
	if g.HLSSplitDiscontinuity != nil && *g.HLSSplitDiscontinuity {
		flags = append(flags, &Flag{ID: "hls_split_discontinuity", Flag: "--hls-split-discontinuity", Args: nil})
	}
	if g.NoHLSSplitDiscontinuity != nil && *g.NoHLSSplitDiscontinuity {
		flags = append(flags, &Flag{ID: "hls_split_discontinuity", Flag: "--no-hls-split-discontinuity", Args: nil})
	}
	for _, v := range g.ExtractorArgs {
		flags = append(flags, &Flag{ID: "extractor_args", Flag: "--extractor-args", AllowsMultiple: true, Args: []any{v}})
	}
	return flags
}
